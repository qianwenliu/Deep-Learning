Sample image grid saved to /Plots with classes:
trees, barren land, water, water, trees, water, road, trees, building, water, water, water, grassland, building, road, water, trees, grassland, water, water, water, grassland, water, trees, water, barren land, water, trees, barren land, water, barren land, water, grassland, trees, water, water, water, grassland, grassland, trees, grassland, water, water, water, barren land, water, grassland, water, grassland, water, building, barren land, trees, water, water, water, barren land, trees, building, grassland, water, grassland, water, trees, barren land, building, water, water, water, water, road, water, barren land, water, trees, building, water, trees, building, water, barren land, water, water, grassland, water, barren land, barren land, trees, trees, barren land, grassland, water, road, water, grassland, water, barren land, water, water, water
NETWORK PARAMETERS:
Batch size: 100
Epochs: 20
Learning rate: 0.001000
Input channels: 4
Input dimensions: 28
Conv kernel size: 4    
NETWORK CONFIGURATION:
0 -> SimpleCNN (
  (conv1): Conv2d(4, 32, kernel_size=(4, 4), stride=(1, 1))
  (pool): MaxPool2d (size=(3, 3), stride=(2, 2), dilation=(1, 1))
  (fc1): Linear (4608 -> 6)
)
1 -> Conv2d(4, 32, kernel_size=(4, 4), stride=(1, 1))
2 -> MaxPool2d (size=(3, 3), stride=(2, 2), dilation=(1, 1))
3 -> Linear (4608 -> 6)
Training loss at epoch 1 of 20, step 100 of 3240: 1.4853
Training loss at epoch 1 of 20, step 200 of 3240: 1.2795
Training loss at epoch 1 of 20, step 300 of 3240: 0.9381
Training loss at epoch 1 of 20, step 400 of 3240: 0.9415
Training loss at epoch 1 of 20, step 500 of 3240: 0.9302
Training loss at epoch 1 of 20, step 600 of 3240: 0.7646
Training loss at epoch 1 of 20, step 700 of 3240: 0.7041
Training loss at epoch 1 of 20, step 800 of 3240: 0.6749
Training loss at epoch 1 of 20, step 900 of 3240: 0.6142
Training loss at epoch 1 of 20, step 1000 of 3240: 0.5312
Training loss at epoch 1 of 20, step 1100 of 3240: 0.5464
Training loss at epoch 1 of 20, step 1200 of 3240: 0.4268
Training loss at epoch 1 of 20, step 1300 of 3240: 0.4762
Training loss at epoch 1 of 20, step 1400 of 3240: 0.4664
Training loss at epoch 1 of 20, step 1500 of 3240: 0.5482
Training loss at epoch 1 of 20, step 1600 of 3240: 0.4687
Training loss at epoch 1 of 20, step 1700 of 3240: 0.4362
Training loss at epoch 1 of 20, step 1800 of 3240: 0.3529
Training loss at epoch 1 of 20, step 1900 of 3240: 0.3344
Training loss at epoch 1 of 20, step 2000 of 3240: 0.3508
Training loss at epoch 1 of 20, step 2100 of 3240: 0.4186
Training loss at epoch 1 of 20, step 2200 of 3240: 0.4009
Training loss at epoch 1 of 20, step 2300 of 3240: 0.2782
Training loss at epoch 1 of 20, step 2400 of 3240: 0.3039
Training loss at epoch 1 of 20, step 2500 of 3240: 0.4290
Training loss at epoch 1 of 20, step 2600 of 3240: 0.3227
Training loss at epoch 1 of 20, step 2700 of 3240: 0.2808
Training loss at epoch 1 of 20, step 2800 of 3240: 0.3882
Training loss at epoch 1 of 20, step 2900 of 3240: 0.2453
Training loss at epoch 1 of 20, step 3000 of 3240: 0.2842
Training loss at epoch 1 of 20, step 3100 of 3240: 0.2950
Training loss at epoch 1 of 20, step 3200 of 3240: 0.2851
Accuracy of network on test set at epoch 1 of 20: 72217/81000 = 89.16%
Training loss at epoch 2 of 20, step 100 of 3240: 0.3108
Training loss at epoch 2 of 20, step 200 of 3240: 0.3590
Training loss at epoch 2 of 20, step 300 of 3240: 0.2447
Training loss at epoch 2 of 20, step 400 of 3240: 0.2874
Training loss at epoch 2 of 20, step 500 of 3240: 0.2267
Training loss at epoch 2 of 20, step 600 of 3240: 0.2719
Training loss at epoch 2 of 20, step 700 of 3240: 0.3210
Training loss at epoch 2 of 20, step 800 of 3240: 0.2180
Training loss at epoch 2 of 20, step 900 of 3240: 0.2370
Training loss at epoch 2 of 20, step 1000 of 3240: 0.2835
Training loss at epoch 2 of 20, step 1100 of 3240: 0.1990
Training loss at epoch 2 of 20, step 1200 of 3240: 0.2465
Training loss at epoch 2 of 20, step 1300 of 3240: 0.2318
Training loss at epoch 2 of 20, step 1400 of 3240: 0.2255
Training loss at epoch 2 of 20, step 1500 of 3240: 0.2955
Training loss at epoch 2 of 20, step 1600 of 3240: 0.2968
Training loss at epoch 2 of 20, step 1700 of 3240: 0.2464
Training loss at epoch 2 of 20, step 1800 of 3240: 0.1896
Training loss at epoch 2 of 20, step 1900 of 3240: 0.2708
Training loss at epoch 2 of 20, step 2000 of 3240: 0.2252
Training loss at epoch 2 of 20, step 2100 of 3240: 0.2443
Training loss at epoch 2 of 20, step 2200 of 3240: 0.1710
Training loss at epoch 2 of 20, step 2300 of 3240: 0.2324
Training loss at epoch 2 of 20, step 2400 of 3240: 0.2131
Training loss at epoch 2 of 20, step 2500 of 3240: 0.2371
Training loss at epoch 2 of 20, step 2600 of 3240: 0.2061
Training loss at epoch 2 of 20, step 2700 of 3240: 0.3111
Training loss at epoch 2 of 20, step 2800 of 3240: 0.2198
Training loss at epoch 2 of 20, step 2900 of 3240: 0.2438
Training loss at epoch 2 of 20, step 3000 of 3240: 0.1935
Training loss at epoch 2 of 20, step 3100 of 3240: 0.2444
Training loss at epoch 2 of 20, step 3200 of 3240: 0.2410
Accuracy of network on test set at epoch 2 of 20: 74697/81000 = 92.22%
Training loss at epoch 3 of 20, step 100 of 3240: 0.2366
Training loss at epoch 3 of 20, step 200 of 3240: 0.1824
Training loss at epoch 3 of 20, step 300 of 3240: 0.2034
Training loss at epoch 3 of 20, step 400 of 3240: 0.1991
Training loss at epoch 3 of 20, step 500 of 3240: 0.1604
Training loss at epoch 3 of 20, step 600 of 3240: 0.2021
Training loss at epoch 3 of 20, step 700 of 3240: 0.2045
Training loss at epoch 3 of 20, step 800 of 3240: 0.1507
Training loss at epoch 3 of 20, step 900 of 3240: 0.2297
Training loss at epoch 3 of 20, step 1000 of 3240: 0.1366
Training loss at epoch 3 of 20, step 1100 of 3240: 0.1656
Training loss at epoch 3 of 20, step 1200 of 3240: 0.2376
Training loss at epoch 3 of 20, step 1300 of 3240: 0.2370
Training loss at epoch 3 of 20, step 1400 of 3240: 0.2502
Training loss at epoch 3 of 20, step 1500 of 3240: 0.1535
Training loss at epoch 3 of 20, step 1600 of 3240: 0.2101
Training loss at epoch 3 of 20, step 1700 of 3240: 0.2134
Training loss at epoch 3 of 20, step 1800 of 3240: 0.2069
Training loss at epoch 3 of 20, step 1900 of 3240: 0.2044
Training loss at epoch 3 of 20, step 2000 of 3240: 0.2290
Training loss at epoch 3 of 20, step 2100 of 3240: 0.1623
Training loss at epoch 3 of 20, step 2200 of 3240: 0.1662
Training loss at epoch 3 of 20, step 2300 of 3240: 0.2394
Training loss at epoch 3 of 20, step 2400 of 3240: 0.1802
Training loss at epoch 3 of 20, step 2500 of 3240: 0.1975
Training loss at epoch 3 of 20, step 2600 of 3240: 0.2386
Training loss at epoch 3 of 20, step 2700 of 3240: 0.2060
Training loss at epoch 3 of 20, step 2800 of 3240: 0.1747
Training loss at epoch 3 of 20, step 2900 of 3240: 0.1786
Training loss at epoch 3 of 20, step 3000 of 3240: 0.2287
Training loss at epoch 3 of 20, step 3100 of 3240: 0.1465
Training loss at epoch 3 of 20, step 3200 of 3240: 0.2332
Accuracy of network on test set at epoch 3 of 20: 75704/81000 = 93.46%
Training loss at epoch 4 of 20, step 100 of 3240: 0.1227
Training loss at epoch 4 of 20, step 200 of 3240: 0.1496
Training loss at epoch 4 of 20, step 300 of 3240: 0.1898
Training loss at epoch 4 of 20, step 400 of 3240: 0.1980
Training loss at epoch 4 of 20, step 500 of 3240: 0.1873
Training loss at epoch 4 of 20, step 600 of 3240: 0.1202
Training loss at epoch 4 of 20, step 700 of 3240: 0.2147
Training loss at epoch 4 of 20, step 800 of 3240: 0.1872
Training loss at epoch 4 of 20, step 900 of 3240: 0.1738
Training loss at epoch 4 of 20, step 1000 of 3240: 0.1206
Training loss at epoch 4 of 20, step 1100 of 3240: 0.2292
Training loss at epoch 4 of 20, step 1200 of 3240: 0.1869
Training loss at epoch 4 of 20, step 1300 of 3240: 0.2203
Training loss at epoch 4 of 20, step 1400 of 3240: 0.1354
Training loss at epoch 4 of 20, step 1500 of 3240: 0.1602
Training loss at epoch 4 of 20, step 1600 of 3240: 0.1612
Training loss at epoch 4 of 20, step 1700 of 3240: 0.1248
Training loss at epoch 4 of 20, step 1800 of 3240: 0.1531
Training loss at epoch 4 of 20, step 1900 of 3240: 0.1673
Training loss at epoch 4 of 20, step 2000 of 3240: 0.1557
Training loss at epoch 4 of 20, step 2100 of 3240: 0.1234
Training loss at epoch 4 of 20, step 2200 of 3240: 0.1997
Training loss at epoch 4 of 20, step 2300 of 3240: 0.1700
Training loss at epoch 4 of 20, step 2400 of 3240: 0.2573
Training loss at epoch 4 of 20, step 2500 of 3240: 0.1449
Training loss at epoch 4 of 20, step 2600 of 3240: 0.1827
Training loss at epoch 4 of 20, step 2700 of 3240: 0.1400
Training loss at epoch 4 of 20, step 2800 of 3240: 0.1428
Training loss at epoch 4 of 20, step 2900 of 3240: 0.1643
Training loss at epoch 4 of 20, step 3000 of 3240: 0.1944
Training loss at epoch 4 of 20, step 3100 of 3240: 0.1141
Training loss at epoch 4 of 20, step 3200 of 3240: 0.1778
Accuracy of network on test set at epoch 4 of 20: 76547/81000 = 94.50%
Training loss at epoch 5 of 20, step 100 of 3240: 0.1961
Training loss at epoch 5 of 20, step 200 of 3240: 0.1674
Training loss at epoch 5 of 20, step 300 of 3240: 0.1187
Training loss at epoch 5 of 20, step 400 of 3240: 0.2608
Training loss at epoch 5 of 20, step 500 of 3240: 0.1383
Training loss at epoch 5 of 20, step 600 of 3240: 0.1281
Training loss at epoch 5 of 20, step 700 of 3240: 0.1278
Training loss at epoch 5 of 20, step 800 of 3240: 0.1890
Training loss at epoch 5 of 20, step 900 of 3240: 0.1693
Training loss at epoch 5 of 20, step 1000 of 3240: 0.1374
Training loss at epoch 5 of 20, step 1100 of 3240: 0.1658
Training loss at epoch 5 of 20, step 1200 of 3240: 0.1706
Training loss at epoch 5 of 20, step 1300 of 3240: 0.1716
Training loss at epoch 5 of 20, step 1400 of 3240: 0.1578
Training loss at epoch 5 of 20, step 1500 of 3240: 0.1501
Training loss at epoch 5 of 20, step 1600 of 3240: 0.2298
Training loss at epoch 5 of 20, step 1700 of 3240: 0.1536
Training loss at epoch 5 of 20, step 1800 of 3240: 0.1884
Training loss at epoch 5 of 20, step 1900 of 3240: 0.1290
Training loss at epoch 5 of 20, step 2000 of 3240: 0.1415
Training loss at epoch 5 of 20, step 2100 of 3240: 0.2516
Training loss at epoch 5 of 20, step 2200 of 3240: 0.2525
Training loss at epoch 5 of 20, step 2300 of 3240: 0.1269
Training loss at epoch 5 of 20, step 2400 of 3240: 0.0752
Training loss at epoch 5 of 20, step 2500 of 3240: 0.2576
Training loss at epoch 5 of 20, step 2600 of 3240: 0.1415
Training loss at epoch 5 of 20, step 2700 of 3240: 0.1152
Training loss at epoch 5 of 20, step 2800 of 3240: 0.1379
Training loss at epoch 5 of 20, step 2900 of 3240: 0.1903
Training loss at epoch 5 of 20, step 3000 of 3240: 0.1549
Training loss at epoch 5 of 20, step 3100 of 3240: 0.1105
Training loss at epoch 5 of 20, step 3200 of 3240: 0.1712
Accuracy of network on test set at epoch 5 of 20: 76921/81000 = 94.96%
Training loss at epoch 6 of 20, step 100 of 3240: 0.0946
Training loss at epoch 6 of 20, step 200 of 3240: 0.1329
Training loss at epoch 6 of 20, step 300 of 3240: 0.1123
Training loss at epoch 6 of 20, step 400 of 3240: 0.1456
Training loss at epoch 6 of 20, step 500 of 3240: 0.2075
Training loss at epoch 6 of 20, step 600 of 3240: 0.1831
Training loss at epoch 6 of 20, step 700 of 3240: 0.1932
Training loss at epoch 6 of 20, step 800 of 3240: 0.1576
Training loss at epoch 6 of 20, step 900 of 3240: 0.1596
Training loss at epoch 6 of 20, step 1000 of 3240: 0.1361
Training loss at epoch 6 of 20, step 1100 of 3240: 0.1367
Training loss at epoch 6 of 20, step 1200 of 3240: 0.1831
Training loss at epoch 6 of 20, step 1300 of 3240: 0.1762
Training loss at epoch 6 of 20, step 1400 of 3240: 0.1197
Training loss at epoch 6 of 20, step 1500 of 3240: 0.1237
Training loss at epoch 6 of 20, step 1600 of 3240: 0.1470
Training loss at epoch 6 of 20, step 1700 of 3240: 0.1061
Training loss at epoch 6 of 20, step 1800 of 3240: 0.1840
Training loss at epoch 6 of 20, step 1900 of 3240: 0.1215
Training loss at epoch 6 of 20, step 2000 of 3240: 0.1027
Training loss at epoch 6 of 20, step 2100 of 3240: 0.1684
Training loss at epoch 6 of 20, step 2200 of 3240: 0.2016
Training loss at epoch 6 of 20, step 2300 of 3240: 0.0734
Training loss at epoch 6 of 20, step 2400 of 3240: 0.1125
Training loss at epoch 6 of 20, step 2500 of 3240: 0.1080
Training loss at epoch 6 of 20, step 2600 of 3240: 0.2118
Training loss at epoch 6 of 20, step 2700 of 3240: 0.1403
Training loss at epoch 6 of 20, step 2800 of 3240: 0.1395
Training loss at epoch 6 of 20, step 2900 of 3240: 0.2021
Training loss at epoch 6 of 20, step 3000 of 3240: 0.1390
Training loss at epoch 6 of 20, step 3100 of 3240: 0.1377
Training loss at epoch 6 of 20, step 3200 of 3240: 0.1820
Accuracy of network on test set at epoch 6 of 20: 77225/81000 = 95.34%
Training loss at epoch 7 of 20, step 100 of 3240: 0.1957
Training loss at epoch 7 of 20, step 200 of 3240: 0.0907
Training loss at epoch 7 of 20, step 300 of 3240: 0.1179
Training loss at epoch 7 of 20, step 400 of 3240: 0.0906
Training loss at epoch 7 of 20, step 500 of 3240: 0.1273
Training loss at epoch 7 of 20, step 600 of 3240: 0.1579
Training loss at epoch 7 of 20, step 700 of 3240: 0.1068
Training loss at epoch 7 of 20, step 800 of 3240: 0.1413
Training loss at epoch 7 of 20, step 900 of 3240: 0.2207
Training loss at epoch 7 of 20, step 1000 of 3240: 0.1240
Training loss at epoch 7 of 20, step 1100 of 3240: 0.1289
Training loss at epoch 7 of 20, step 1200 of 3240: 0.1173
Training loss at epoch 7 of 20, step 1300 of 3240: 0.2021
Training loss at epoch 7 of 20, step 1400 of 3240: 0.1110
Training loss at epoch 7 of 20, step 1500 of 3240: 0.1372
Training loss at epoch 7 of 20, step 1600 of 3240: 0.1441
Training loss at epoch 7 of 20, step 1700 of 3240: 0.1829
Training loss at epoch 7 of 20, step 1800 of 3240: 0.1025
Training loss at epoch 7 of 20, step 1900 of 3240: 0.1333
Training loss at epoch 7 of 20, step 2000 of 3240: 0.1412
Training loss at epoch 7 of 20, step 2100 of 3240: 0.1296
Training loss at epoch 7 of 20, step 2200 of 3240: 0.1519
Training loss at epoch 7 of 20, step 2300 of 3240: 0.1240
Training loss at epoch 7 of 20, step 2400 of 3240: 0.1389
Training loss at epoch 7 of 20, step 2500 of 3240: 0.1236
Training loss at epoch 7 of 20, step 2600 of 3240: 0.1534
Training loss at epoch 7 of 20, step 2700 of 3240: 0.0858
Training loss at epoch 7 of 20, step 2800 of 3240: 0.1120
Training loss at epoch 7 of 20, step 2900 of 3240: 0.1486
Training loss at epoch 7 of 20, step 3000 of 3240: 0.1559
Training loss at epoch 7 of 20, step 3100 of 3240: 0.1955
Training loss at epoch 7 of 20, step 3200 of 3240: 0.2060
Accuracy of network on test set at epoch 7 of 20: 77514/81000 = 95.70%
Training loss at epoch 8 of 20, step 100 of 3240: 0.1330
Training loss at epoch 8 of 20, step 200 of 3240: 0.2552
Training loss at epoch 8 of 20, step 300 of 3240: 0.1179
Training loss at epoch 8 of 20, step 400 of 3240: 0.1174
Training loss at epoch 8 of 20, step 500 of 3240: 0.1353
Training loss at epoch 8 of 20, step 600 of 3240: 0.1345
Training loss at epoch 8 of 20, step 700 of 3240: 0.1073
Training loss at epoch 8 of 20, step 800 of 3240: 0.1759
Training loss at epoch 8 of 20, step 900 of 3240: 0.1254
Training loss at epoch 8 of 20, step 1000 of 3240: 0.1566
Training loss at epoch 8 of 20, step 1100 of 3240: 0.0812
Training loss at epoch 8 of 20, step 1200 of 3240: 0.1386
Training loss at epoch 8 of 20, step 1300 of 3240: 0.1199
Training loss at epoch 8 of 20, step 1400 of 3240: 0.1348
Training loss at epoch 8 of 20, step 1500 of 3240: 0.3258
Training loss at epoch 8 of 20, step 1600 of 3240: 0.1384
Training loss at epoch 8 of 20, step 1700 of 3240: 0.1208
Training loss at epoch 8 of 20, step 1800 of 3240: 0.1696
Training loss at epoch 8 of 20, step 1900 of 3240: 0.1090
Training loss at epoch 8 of 20, step 2000 of 3240: 0.1230
Training loss at epoch 8 of 20, step 2100 of 3240: 0.1257
Training loss at epoch 8 of 20, step 2200 of 3240: 0.0950
Training loss at epoch 8 of 20, step 2300 of 3240: 0.1316
Training loss at epoch 8 of 20, step 2400 of 3240: 0.0899
Training loss at epoch 8 of 20, step 2500 of 3240: 0.1598
Training loss at epoch 8 of 20, step 2600 of 3240: 0.1698
Training loss at epoch 8 of 20, step 2700 of 3240: 0.1378
Training loss at epoch 8 of 20, step 2800 of 3240: 0.1606
Training loss at epoch 8 of 20, step 2900 of 3240: 0.1126
Training loss at epoch 8 of 20, step 3000 of 3240: 0.1171
Training loss at epoch 8 of 20, step 3100 of 3240: 0.1289
Training loss at epoch 8 of 20, step 3200 of 3240: 0.1535
Accuracy of network on test set at epoch 8 of 20: 78064/81000 = 96.38%
Training loss at epoch 9 of 20, step 100 of 3240: 0.1281
Training loss at epoch 9 of 20, step 200 of 3240: 0.1154
Training loss at epoch 9 of 20, step 300 of 3240: 0.1293
Training loss at epoch 9 of 20, step 400 of 3240: 0.1175
Training loss at epoch 9 of 20, step 500 of 3240: 0.1244
Training loss at epoch 9 of 20, step 600 of 3240: 0.1775
Training loss at epoch 9 of 20, step 700 of 3240: 0.1664
Training loss at epoch 9 of 20, step 800 of 3240: 0.1115
Training loss at epoch 9 of 20, step 900 of 3240: 0.1900
Training loss at epoch 9 of 20, step 1000 of 3240: 0.1113
Training loss at epoch 9 of 20, step 1100 of 3240: 0.0999
Training loss at epoch 9 of 20, step 1200 of 3240: 0.1264
Training loss at epoch 9 of 20, step 1300 of 3240: 0.1797
Training loss at epoch 9 of 20, step 1400 of 3240: 0.1958
Training loss at epoch 9 of 20, step 1500 of 3240: 0.0788
Training loss at epoch 9 of 20, step 1600 of 3240: 0.0574
Training loss at epoch 9 of 20, step 1700 of 3240: 0.1345
Training loss at epoch 9 of 20, step 1800 of 3240: 0.0781
Training loss at epoch 9 of 20, step 1900 of 3240: 0.1120
Training loss at epoch 9 of 20, step 2000 of 3240: 0.0879
Training loss at epoch 9 of 20, step 2100 of 3240: 0.0988
Training loss at epoch 9 of 20, step 2200 of 3240: 0.0947
Training loss at epoch 9 of 20, step 2300 of 3240: 0.1311
Training loss at epoch 9 of 20, step 2400 of 3240: 0.0930
Training loss at epoch 9 of 20, step 2500 of 3240: 0.1757
Training loss at epoch 9 of 20, step 2600 of 3240: 0.0710
Training loss at epoch 9 of 20, step 2700 of 3240: 0.2595
Training loss at epoch 9 of 20, step 2800 of 3240: 0.1274
Training loss at epoch 9 of 20, step 2900 of 3240: 0.0826
Training loss at epoch 9 of 20, step 3000 of 3240: 0.1580
Training loss at epoch 9 of 20, step 3100 of 3240: 0.1134
Training loss at epoch 9 of 20, step 3200 of 3240: 0.0942
Accuracy of network on test set at epoch 9 of 20: 78203/81000 = 96.55%
Training loss at epoch 10 of 20, step 100 of 3240: 0.1280
Training loss at epoch 10 of 20, step 200 of 3240: 0.0497
Training loss at epoch 10 of 20, step 300 of 3240: 0.1187
Training loss at epoch 10 of 20, step 400 of 3240: 0.0974
Training loss at epoch 10 of 20, step 500 of 3240: 0.1237
Training loss at epoch 10 of 20, step 600 of 3240: 0.1354
Training loss at epoch 10 of 20, step 700 of 3240: 0.1315
Training loss at epoch 10 of 20, step 800 of 3240: 0.1318
Training loss at epoch 10 of 20, step 900 of 3240: 0.2281
Training loss at epoch 10 of 20, step 1000 of 3240: 0.0918
Training loss at epoch 10 of 20, step 1100 of 3240: 0.1501
Training loss at epoch 10 of 20, step 1200 of 3240: 0.0773
Training loss at epoch 10 of 20, step 1300 of 3240: 0.1015
Training loss at epoch 10 of 20, step 1400 of 3240: 0.1224
Training loss at epoch 10 of 20, step 1500 of 3240: 0.1291
Training loss at epoch 10 of 20, step 1600 of 3240: 0.0986
Training loss at epoch 10 of 20, step 1700 of 3240: 0.0930
Training loss at epoch 10 of 20, step 1800 of 3240: 0.1781
Training loss at epoch 10 of 20, step 1900 of 3240: 0.1036
Training loss at epoch 10 of 20, step 2000 of 3240: 0.0888
Training loss at epoch 10 of 20, step 2100 of 3240: 0.1071
Training loss at epoch 10 of 20, step 2200 of 3240: 0.0620
Training loss at epoch 10 of 20, step 2300 of 3240: 0.1021
Training loss at epoch 10 of 20, step 2400 of 3240: 0.1773
Training loss at epoch 10 of 20, step 2500 of 3240: 0.0861
Training loss at epoch 10 of 20, step 2600 of 3240: 0.0918
Training loss at epoch 10 of 20, step 2700 of 3240: 0.0893
Training loss at epoch 10 of 20, step 2800 of 3240: 0.0952
Training loss at epoch 10 of 20, step 2900 of 3240: 0.1057
Training loss at epoch 10 of 20, step 3000 of 3240: 0.0496
Training loss at epoch 10 of 20, step 3100 of 3240: 0.0851
Training loss at epoch 10 of 20, step 3200 of 3240: 0.1079
Accuracy of network on test set at epoch 10 of 20: 78324/81000 = 96.70%
Training loss at epoch 11 of 20, step 100 of 3240: 0.1451
Training loss at epoch 11 of 20, step 200 of 3240: 0.0609
Training loss at epoch 11 of 20, step 300 of 3240: 0.0733
Training loss at epoch 11 of 20, step 400 of 3240: 0.1119
Training loss at epoch 11 of 20, step 500 of 3240: 0.0811
Training loss at epoch 11 of 20, step 600 of 3240: 0.1306
Training loss at epoch 11 of 20, step 700 of 3240: 0.1035
Training loss at epoch 11 of 20, step 800 of 3240: 0.1144
Training loss at epoch 11 of 20, step 900 of 3240: 0.1209
Training loss at epoch 11 of 20, step 1000 of 3240: 0.1572
Training loss at epoch 11 of 20, step 1100 of 3240: 0.2393
Training loss at epoch 11 of 20, step 1200 of 3240: 0.0845
Training loss at epoch 11 of 20, step 1300 of 3240: 0.1032
Training loss at epoch 11 of 20, step 1400 of 3240: 0.2569
Training loss at epoch 11 of 20, step 1500 of 3240: 0.1178
Training loss at epoch 11 of 20, step 1600 of 3240: 0.1936
Training loss at epoch 11 of 20, step 1700 of 3240: 0.1281
Training loss at epoch 11 of 20, step 1800 of 3240: 0.1480
Training loss at epoch 11 of 20, step 1900 of 3240: 0.1496
Training loss at epoch 11 of 20, step 2000 of 3240: 0.1028
Training loss at epoch 11 of 20, step 2100 of 3240: 0.1350
Training loss at epoch 11 of 20, step 2200 of 3240: 0.1190
Training loss at epoch 11 of 20, step 2300 of 3240: 0.0873
Training loss at epoch 11 of 20, step 2400 of 3240: 0.0887
Training loss at epoch 11 of 20, step 2500 of 3240: 0.1161
Training loss at epoch 11 of 20, step 2600 of 3240: 0.0671
Training loss at epoch 11 of 20, step 2700 of 3240: 0.0488
Training loss at epoch 11 of 20, step 2800 of 3240: 0.1527
Training loss at epoch 11 of 20, step 2900 of 3240: 0.1085
Training loss at epoch 11 of 20, step 3000 of 3240: 0.1119
Training loss at epoch 11 of 20, step 3100 of 3240: 0.0735
Training loss at epoch 11 of 20, step 3200 of 3240: 0.1629
Accuracy of network on test set at epoch 11 of 20: 78391/81000 = 96.78%
Training loss at epoch 12 of 20, step 100 of 3240: 0.1147
Training loss at epoch 12 of 20, step 200 of 3240: 0.2002
Training loss at epoch 12 of 20, step 300 of 3240: 0.0774
Training loss at epoch 12 of 20, step 400 of 3240: 0.0782
Training loss at epoch 12 of 20, step 500 of 3240: 0.0799
Training loss at epoch 12 of 20, step 600 of 3240: 0.1420
Training loss at epoch 12 of 20, step 700 of 3240: 0.0644
Training loss at epoch 12 of 20, step 800 of 3240: 0.0946
Training loss at epoch 12 of 20, step 900 of 3240: 0.0827
Training loss at epoch 12 of 20, step 1000 of 3240: 0.1042
Training loss at epoch 12 of 20, step 1100 of 3240: 0.0792
Training loss at epoch 12 of 20, step 1200 of 3240: 0.1007
Training loss at epoch 12 of 20, step 1300 of 3240: 0.1261
Training loss at epoch 12 of 20, step 1400 of 3240: 0.1134
Training loss at epoch 12 of 20, step 1500 of 3240: 0.1179
Training loss at epoch 12 of 20, step 1600 of 3240: 0.1115
Training loss at epoch 12 of 20, step 1700 of 3240: 0.1320
Training loss at epoch 12 of 20, step 1800 of 3240: 0.1235
Training loss at epoch 12 of 20, step 1900 of 3240: 0.0837
Training loss at epoch 12 of 20, step 2000 of 3240: 0.0697
Training loss at epoch 12 of 20, step 2100 of 3240: 0.0728
Training loss at epoch 12 of 20, step 2200 of 3240: 0.0788
Training loss at epoch 12 of 20, step 2300 of 3240: 0.0578
Training loss at epoch 12 of 20, step 2400 of 3240: 0.0942
Training loss at epoch 12 of 20, step 2500 of 3240: 0.1345
Training loss at epoch 12 of 20, step 2600 of 3240: 0.1170
Training loss at epoch 12 of 20, step 2700 of 3240: 0.0766
Training loss at epoch 12 of 20, step 2800 of 3240: 0.0948
Training loss at epoch 12 of 20, step 2900 of 3240: 0.0631
Training loss at epoch 12 of 20, step 3000 of 3240: 0.0609
Training loss at epoch 12 of 20, step 3100 of 3240: 0.0921
Training loss at epoch 12 of 20, step 3200 of 3240: 0.1608
Accuracy of network on test set at epoch 12 of 20: 78445/81000 = 96.85%
Training loss at epoch 13 of 20, step 100 of 3240: 0.1577
Training loss at epoch 13 of 20, step 200 of 3240: 0.1317
Training loss at epoch 13 of 20, step 300 of 3240: 0.1122
Training loss at epoch 13 of 20, step 400 of 3240: 0.1123
Training loss at epoch 13 of 20, step 500 of 3240: 0.1506
Training loss at epoch 13 of 20, step 600 of 3240: 0.0767
Training loss at epoch 13 of 20, step 700 of 3240: 0.0644
Training loss at epoch 13 of 20, step 800 of 3240: 0.1042
Training loss at epoch 13 of 20, step 900 of 3240: 0.1482
Training loss at epoch 13 of 20, step 1000 of 3240: 0.0752
Training loss at epoch 13 of 20, step 1100 of 3240: 0.2246
Training loss at epoch 13 of 20, step 1200 of 3240: 0.2316
Training loss at epoch 13 of 20, step 1300 of 3240: 0.1082
Training loss at epoch 13 of 20, step 1400 of 3240: 0.0802
Training loss at epoch 13 of 20, step 1500 of 3240: 0.1501
Training loss at epoch 13 of 20, step 1600 of 3240: 0.1012
Training loss at epoch 13 of 20, step 1700 of 3240: 0.1305
Training loss at epoch 13 of 20, step 1800 of 3240: 0.1118
Training loss at epoch 13 of 20, step 1900 of 3240: 0.0724
Training loss at epoch 13 of 20, step 2000 of 3240: 0.0996
Training loss at epoch 13 of 20, step 2100 of 3240: 0.1127
Training loss at epoch 13 of 20, step 2200 of 3240: 0.0767
Training loss at epoch 13 of 20, step 2300 of 3240: 0.1665
Training loss at epoch 13 of 20, step 2400 of 3240: 0.1119
Training loss at epoch 13 of 20, step 2500 of 3240: 0.1159
Training loss at epoch 13 of 20, step 2600 of 3240: 0.1209
Training loss at epoch 13 of 20, step 2700 of 3240: 0.0715
Training loss at epoch 13 of 20, step 2800 of 3240: 0.0758
Training loss at epoch 13 of 20, step 2900 of 3240: 0.1111
Training loss at epoch 13 of 20, step 3000 of 3240: 0.0768
Training loss at epoch 13 of 20, step 3100 of 3240: 0.1055
Training loss at epoch 13 of 20, step 3200 of 3240: 0.1037
Accuracy of network on test set at epoch 13 of 20: 78516/81000 = 96.93%
Training loss at epoch 14 of 20, step 100 of 3240: 0.0302
Training loss at epoch 14 of 20, step 200 of 3240: 0.0736
Training loss at epoch 14 of 20, step 300 of 3240: 0.0555
Training loss at epoch 14 of 20, step 400 of 3240: 0.1322
Training loss at epoch 14 of 20, step 500 of 3240: 0.1120
Training loss at epoch 14 of 20, step 600 of 3240: 0.1092
Training loss at epoch 14 of 20, step 700 of 3240: 0.0910
Training loss at epoch 14 of 20, step 800 of 3240: 0.1007
Training loss at epoch 14 of 20, step 900 of 3240: 0.0768
Training loss at epoch 14 of 20, step 1000 of 3240: 0.0748
Training loss at epoch 14 of 20, step 1100 of 3240: 0.0912
Training loss at epoch 14 of 20, step 1200 of 3240: 0.1178
Training loss at epoch 14 of 20, step 1300 of 3240: 0.0687
Training loss at epoch 14 of 20, step 1400 of 3240: 0.1086
Training loss at epoch 14 of 20, step 1500 of 3240: 0.0853
Training loss at epoch 14 of 20, step 1600 of 3240: 0.0433
Training loss at epoch 14 of 20, step 1700 of 3240: 0.1541
Training loss at epoch 14 of 20, step 1800 of 3240: 0.0802
Training loss at epoch 14 of 20, step 1900 of 3240: 0.1113
Training loss at epoch 14 of 20, step 2000 of 3240: 0.0796
Training loss at epoch 14 of 20, step 2100 of 3240: 0.0998
Training loss at epoch 14 of 20, step 2200 of 3240: 0.1653
Training loss at epoch 14 of 20, step 2300 of 3240: 0.0691
Training loss at epoch 14 of 20, step 2400 of 3240: 0.0768
Training loss at epoch 14 of 20, step 2500 of 3240: 0.1227
Training loss at epoch 14 of 20, step 2600 of 3240: 0.0999
Training loss at epoch 14 of 20, step 2700 of 3240: 0.1129
Training loss at epoch 14 of 20, step 2800 of 3240: 0.0976
Training loss at epoch 14 of 20, step 2900 of 3240: 0.0770
Training loss at epoch 14 of 20, step 3000 of 3240: 0.0889
Training loss at epoch 14 of 20, step 3100 of 3240: 0.0964
Training loss at epoch 14 of 20, step 3200 of 3240: 0.1788
Accuracy of network on test set at epoch 14 of 20: 78612/81000 = 97.05%
Training loss at epoch 15 of 20, step 100 of 3240: 0.0732
Training loss at epoch 15 of 20, step 200 of 3240: 0.1200
Training loss at epoch 15 of 20, step 300 of 3240: 0.0846
Training loss at epoch 15 of 20, step 400 of 3240: 0.1228
Training loss at epoch 15 of 20, step 500 of 3240: 0.1532
Training loss at epoch 15 of 20, step 600 of 3240: 0.1164
Training loss at epoch 15 of 20, step 700 of 3240: 0.1331
Training loss at epoch 15 of 20, step 800 of 3240: 0.0345
Training loss at epoch 15 of 20, step 900 of 3240: 0.0781
Training loss at epoch 15 of 20, step 1000 of 3240: 0.0936
Training loss at epoch 15 of 20, step 1100 of 3240: 0.1001
Training loss at epoch 15 of 20, step 1200 of 3240: 0.0844
Training loss at epoch 15 of 20, step 1300 of 3240: 0.0891
Training loss at epoch 15 of 20, step 1400 of 3240: 0.1038
Training loss at epoch 15 of 20, step 1500 of 3240: 0.1137
Training loss at epoch 15 of 20, step 1600 of 3240: 0.1005
Training loss at epoch 15 of 20, step 1700 of 3240: 0.0989
Training loss at epoch 15 of 20, step 1800 of 3240: 0.0937
Training loss at epoch 15 of 20, step 1900 of 3240: 0.1523
Training loss at epoch 15 of 20, step 2000 of 3240: 0.0567
Training loss at epoch 15 of 20, step 2100 of 3240: 0.1651
Training loss at epoch 15 of 20, step 2200 of 3240: 0.0672
Training loss at epoch 15 of 20, step 2300 of 3240: 0.1203
Training loss at epoch 15 of 20, step 2400 of 3240: 0.0717
Training loss at epoch 15 of 20, step 2500 of 3240: 0.0672
Training loss at epoch 15 of 20, step 2600 of 3240: 0.0709
Training loss at epoch 15 of 20, step 2700 of 3240: 0.1356
Training loss at epoch 15 of 20, step 2800 of 3240: 0.1192
Training loss at epoch 15 of 20, step 2900 of 3240: 0.0820
Training loss at epoch 15 of 20, step 3000 of 3240: 0.0856
Training loss at epoch 15 of 20, step 3100 of 3240: 0.1015
Training loss at epoch 15 of 20, step 3200 of 3240: 0.1255
Accuracy of network on test set at epoch 15 of 20: 78621/81000 = 97.06%
Training loss at epoch 16 of 20, step 100 of 3240: 0.1480
Training loss at epoch 16 of 20, step 200 of 3240: 0.0630
Training loss at epoch 16 of 20, step 300 of 3240: 0.1118
Training loss at epoch 16 of 20, step 400 of 3240: 0.0805
Training loss at epoch 16 of 20, step 500 of 3240: 0.0980
Training loss at epoch 16 of 20, step 600 of 3240: 0.0736
Training loss at epoch 16 of 20, step 700 of 3240: 0.0777
Training loss at epoch 16 of 20, step 800 of 3240: 0.1318
Training loss at epoch 16 of 20, step 900 of 3240: 0.0776
Training loss at epoch 16 of 20, step 1000 of 3240: 0.1041
Training loss at epoch 16 of 20, step 1100 of 3240: 0.0612
Training loss at epoch 16 of 20, step 1200 of 3240: 0.0723
Training loss at epoch 16 of 20, step 1300 of 3240: 0.0685
Training loss at epoch 16 of 20, step 1400 of 3240: 0.1212
Training loss at epoch 16 of 20, step 1500 of 3240: 0.0951
Training loss at epoch 16 of 20, step 1600 of 3240: 0.0703
Training loss at epoch 16 of 20, step 1700 of 3240: 0.1143
Training loss at epoch 16 of 20, step 1800 of 3240: 0.0920
Training loss at epoch 16 of 20, step 1900 of 3240: 0.1094
Training loss at epoch 16 of 20, step 2000 of 3240: 0.1007
Training loss at epoch 16 of 20, step 2100 of 3240: 0.0708
Training loss at epoch 16 of 20, step 2200 of 3240: 0.0828
Training loss at epoch 16 of 20, step 2300 of 3240: 0.0759
Training loss at epoch 16 of 20, step 2400 of 3240: 0.1193
Training loss at epoch 16 of 20, step 2500 of 3240: 0.1006
Training loss at epoch 16 of 20, step 2600 of 3240: 0.1100
Training loss at epoch 16 of 20, step 2700 of 3240: 0.0981
Training loss at epoch 16 of 20, step 2800 of 3240: 0.1026
Training loss at epoch 16 of 20, step 2900 of 3240: 0.0829
Training loss at epoch 16 of 20, step 3000 of 3240: 0.0588
Training loss at epoch 16 of 20, step 3100 of 3240: 0.0844
Training loss at epoch 16 of 20, step 3200 of 3240: 0.1305
Accuracy of network on test set at epoch 16 of 20: 78579/81000 = 97.01%
Training loss at epoch 17 of 20, step 100 of 3240: 0.0561
Training loss at epoch 17 of 20, step 200 of 3240: 0.0829
Training loss at epoch 17 of 20, step 300 of 3240: 0.0761
Training loss at epoch 17 of 20, step 400 of 3240: 0.0802
Training loss at epoch 17 of 20, step 500 of 3240: 0.0894
Training loss at epoch 17 of 20, step 600 of 3240: 0.1547
Training loss at epoch 17 of 20, step 700 of 3240: 0.1032
Training loss at epoch 17 of 20, step 800 of 3240: 0.0705
Training loss at epoch 17 of 20, step 900 of 3240: 0.0936
Training loss at epoch 17 of 20, step 1000 of 3240: 0.1377
Training loss at epoch 17 of 20, step 1100 of 3240: 0.0604
Training loss at epoch 17 of 20, step 1200 of 3240: 0.0715
Training loss at epoch 17 of 20, step 1300 of 3240: 0.1273
Training loss at epoch 17 of 20, step 1400 of 3240: 0.0597
Training loss at epoch 17 of 20, step 1500 of 3240: 0.1200
Training loss at epoch 17 of 20, step 1600 of 3240: 0.0951
Training loss at epoch 17 of 20, step 1700 of 3240: 0.0829
Training loss at epoch 17 of 20, step 1800 of 3240: 0.0707
Training loss at epoch 17 of 20, step 1900 of 3240: 0.1548
Training loss at epoch 17 of 20, step 2000 of 3240: 0.0548
Training loss at epoch 17 of 20, step 2100 of 3240: 0.1549
Training loss at epoch 17 of 20, step 2200 of 3240: 0.0827
Training loss at epoch 17 of 20, step 2300 of 3240: 0.1711
Training loss at epoch 17 of 20, step 2400 of 3240: 0.0838
Training loss at epoch 17 of 20, step 2500 of 3240: 0.0930
Training loss at epoch 17 of 20, step 2600 of 3240: 0.0963
Training loss at epoch 17 of 20, step 2700 of 3240: 0.0785
Training loss at epoch 17 of 20, step 2800 of 3240: 0.1334
Training loss at epoch 17 of 20, step 2900 of 3240: 0.0796
Training loss at epoch 17 of 20, step 3000 of 3240: 0.1103
Training loss at epoch 17 of 20, step 3100 of 3240: 0.0681
Training loss at epoch 17 of 20, step 3200 of 3240: 0.1932
Accuracy of network on test set at epoch 17 of 20: 78735/81000 = 97.20%
Training loss at epoch 18 of 20, step 100 of 3240: 0.0375
Training loss at epoch 18 of 20, step 200 of 3240: 0.0525
Training loss at epoch 18 of 20, step 300 of 3240: 0.0969
Training loss at epoch 18 of 20, step 400 of 3240: 0.0988
Training loss at epoch 18 of 20, step 500 of 3240: 0.0356
Training loss at epoch 18 of 20, step 600 of 3240: 0.0946
Training loss at epoch 18 of 20, step 700 of 3240: 0.0833
Training loss at epoch 18 of 20, step 800 of 3240: 0.1120
Training loss at epoch 18 of 20, step 900 of 3240: 0.1034
Training loss at epoch 18 of 20, step 1000 of 3240: 0.0953
Training loss at epoch 18 of 20, step 1100 of 3240: 0.1016
Training loss at epoch 18 of 20, step 1200 of 3240: 0.0588
Training loss at epoch 18 of 20, step 1300 of 3240: 0.0953
Training loss at epoch 18 of 20, step 1400 of 3240: 0.0796
Training loss at epoch 18 of 20, step 1500 of 3240: 0.0871
Training loss at epoch 18 of 20, step 1600 of 3240: 0.1061
Training loss at epoch 18 of 20, step 1700 of 3240: 0.0937
Training loss at epoch 18 of 20, step 1800 of 3240: 0.1060
Training loss at epoch 18 of 20, step 1900 of 3240: 0.1012
Training loss at epoch 18 of 20, step 2000 of 3240: 0.0853
Training loss at epoch 18 of 20, step 2100 of 3240: 0.1115
Training loss at epoch 18 of 20, step 2200 of 3240: 0.0993
Training loss at epoch 18 of 20, step 2300 of 3240: 0.0263
Training loss at epoch 18 of 20, step 2400 of 3240: 0.1046
Training loss at epoch 18 of 20, step 2500 of 3240: 0.0332
Training loss at epoch 18 of 20, step 2600 of 3240: 0.1190
Training loss at epoch 18 of 20, step 2700 of 3240: 0.0616
Training loss at epoch 18 of 20, step 2800 of 3240: 0.0536
Training loss at epoch 18 of 20, step 2900 of 3240: 0.0848
Training loss at epoch 18 of 20, step 3000 of 3240: 0.0991
Training loss at epoch 18 of 20, step 3100 of 3240: 0.0661
Training loss at epoch 18 of 20, step 3200 of 3240: 0.1041
Accuracy of network on test set at epoch 18 of 20: 78759/81000 = 97.23%
Training loss at epoch 19 of 20, step 100 of 3240: 0.1154
Training loss at epoch 19 of 20, step 200 of 3240: 0.0441
Training loss at epoch 19 of 20, step 300 of 3240: 0.0423
Training loss at epoch 19 of 20, step 400 of 3240: 0.0437
Training loss at epoch 19 of 20, step 500 of 3240: 0.1167
Training loss at epoch 19 of 20, step 600 of 3240: 0.0750
Training loss at epoch 19 of 20, step 700 of 3240: 0.0670
Training loss at epoch 19 of 20, step 800 of 3240: 0.0774
Training loss at epoch 19 of 20, step 900 of 3240: 0.0540
Training loss at epoch 19 of 20, step 1000 of 3240: 0.0778
Training loss at epoch 19 of 20, step 1100 of 3240: 0.1247
Training loss at epoch 19 of 20, step 1200 of 3240: 0.0539
Training loss at epoch 19 of 20, step 1300 of 3240: 0.0528
Training loss at epoch 19 of 20, step 1400 of 3240: 0.0718
Training loss at epoch 19 of 20, step 1500 of 3240: 0.0933
Training loss at epoch 19 of 20, step 1600 of 3240: 0.0706
Training loss at epoch 19 of 20, step 1700 of 3240: 0.0919
Training loss at epoch 19 of 20, step 1800 of 3240: 0.0789
Training loss at epoch 19 of 20, step 1900 of 3240: 0.0424
Training loss at epoch 19 of 20, step 2000 of 3240: 0.0762
Training loss at epoch 19 of 20, step 2100 of 3240: 0.0660
Training loss at epoch 19 of 20, step 2200 of 3240: 0.0888
Training loss at epoch 19 of 20, step 2300 of 3240: 0.0505
Training loss at epoch 19 of 20, step 2400 of 3240: 0.0694
Training loss at epoch 19 of 20, step 2500 of 3240: 0.0675
Training loss at epoch 19 of 20, step 2600 of 3240: 0.1073
Training loss at epoch 19 of 20, step 2700 of 3240: 0.1084
Training loss at epoch 19 of 20, step 2800 of 3240: 0.0614
Training loss at epoch 19 of 20, step 2900 of 3240: 0.0740
Training loss at epoch 19 of 20, step 3000 of 3240: 0.1988
Training loss at epoch 19 of 20, step 3100 of 3240: 0.0466
Training loss at epoch 19 of 20, step 3200 of 3240: 0.1730
Accuracy of network on test set at epoch 19 of 20: 78512/81000 = 96.93%
Training loss at epoch 20 of 20, step 100 of 3240: 0.1604
Training loss at epoch 20 of 20, step 200 of 3240: 0.0660
Training loss at epoch 20 of 20, step 300 of 3240: 0.0956
Training loss at epoch 20 of 20, step 400 of 3240: 0.0996
Training loss at epoch 20 of 20, step 500 of 3240: 0.0597
Training loss at epoch 20 of 20, step 600 of 3240: 0.0593
Training loss at epoch 20 of 20, step 700 of 3240: 0.1159
Training loss at epoch 20 of 20, step 800 of 3240: 0.1105
Training loss at epoch 20 of 20, step 900 of 3240: 0.0705
Training loss at epoch 20 of 20, step 1000 of 3240: 0.0762
Training loss at epoch 20 of 20, step 1100 of 3240: 0.1804
Training loss at epoch 20 of 20, step 1200 of 3240: 0.0579
Training loss at epoch 20 of 20, step 1300 of 3240: 0.0724
Training loss at epoch 20 of 20, step 1400 of 3240: 0.0538
Training loss at epoch 20 of 20, step 1500 of 3240: 0.0903
Training loss at epoch 20 of 20, step 1600 of 3240: 0.0323
Training loss at epoch 20 of 20, step 1700 of 3240: 0.0629
Training loss at epoch 20 of 20, step 1800 of 3240: 0.0855
Training loss at epoch 20 of 20, step 1900 of 3240: 0.1091
Training loss at epoch 20 of 20, step 2000 of 3240: 0.1294
Training loss at epoch 20 of 20, step 2100 of 3240: 0.0678
Training loss at epoch 20 of 20, step 2200 of 3240: 0.0671
Training loss at epoch 20 of 20, step 2300 of 3240: 0.2517
Training loss at epoch 20 of 20, step 2400 of 3240: 0.0967
Training loss at epoch 20 of 20, step 2500 of 3240: 0.1500
Training loss at epoch 20 of 20, step 2600 of 3240: 0.0900
Training loss at epoch 20 of 20, step 2700 of 3240: 0.0551
Training loss at epoch 20 of 20, step 2800 of 3240: 0.0888
Training loss at epoch 20 of 20, step 2900 of 3240: 0.0677
Training loss at epoch 20 of 20, step 3000 of 3240: 0.1461
Training loss at epoch 20 of 20, step 3100 of 3240: 0.0932
Training loss at epoch 20 of 20, step 3200 of 3240: 0.2339
Accuracy of network on test set at epoch 20 of 20: 78797/81000 = 97.28%
Training time: 5594.8 seconds.
Training loss plot saved in /Plots.
Testing Accuracy plot saved in /Plots.
             building  barren land  trees  grassland  road  water
building         3641            5      0          2   218      0
barren land         2        17512      2        408     2      0
trees               6           14  13939        263    10      0
grassland           6          831    244      11894    48      0
road               59            5      0         29  1743      0
water               0            0      0          0    49  30068
Accuracy rate: 97.28%
Misclassifcation rate: 2.72%
Confusion matrix plot saved in /Plots.
kernels plot saved in /Plots.
