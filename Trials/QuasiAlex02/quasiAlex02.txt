Sample image grid saved to /Plots with classes:
building, grassland, water, barren land, barren land, barren land, water, trees, trees, water, barren land, water, water, trees, water, water, barren land, water, water, grassland, trees, trees, trees, trees, grassland, water, trees, water, water, trees, water, grassland, trees, water, grassland, water, water, water, trees, grassland, water, water, trees, barren land, barren land, water, water, trees, water, barren land, barren land, water, barren land, water, trees, trees, trees, grassland, water, grassland, barren land, barren land, barren land, water, building, water, trees, water, grassland, water, water, trees, trees, grassland, water, water, barren land, trees, barren land, water, water, trees, trees, water, barren land, water, road, barren land, grassland, trees, grassland, water, barren land, grassland, trees, road, trees, trees, building, building
NETWORK PARAMETERS:
Batch size: 100
Epochs: 10
Learning rate: 0.005000
Momentum: 0.950000
Weight Decay: 0.000500
Input channels: 4
Input dimensions: 28

NETWORK CONFIGURATION:
0 -> QuasiAlex (
  (conv1): Conv2d(4, 12, kernel_size=(11, 11), stride=(1, 1))
  (conv2): Conv2d(12, 32, kernel_size=(5, 5), stride=(1, 1))
  (conv3): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1))
  (conv4): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv5): Conv2d(48, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (pool): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))
  (fc1): Linear (1152 -> 24)
  (fc2): Linear (24 -> 24)
  (fc3): Linear (24 -> 6)
)
1 -> Conv2d(4, 12, kernel_size=(11, 11), stride=(1, 1))
2 -> Conv2d(12, 32, kernel_size=(5, 5), stride=(1, 1))
3 -> Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1))
4 -> Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
5 -> Conv2d(48, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
6 -> MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))
7 -> Linear (1152 -> 24)
8 -> Linear (24 -> 24)
9 -> Linear (24 -> 6)
Accuracy of network on test set at epoch 1 of 10: 160/1000 = 16.00%
Accuracy of network on test set at epoch 2 of 10: 351/1000 = 35.10%
Accuracy of network on test set at epoch 3 of 10: 351/1000 = 35.10%
Accuracy of network on test set at epoch 4 of 10: 351/1000 = 35.10%
Accuracy of network on test set at epoch 5 of 10: 351/1000 = 35.10%
Accuracy of network on test set at epoch 6 of 10: 351/1000 = 35.10%
Accuracy of network on test set at epoch 7 of 10: 351/1000 = 35.10%
Accuracy of network on test set at epoch 8 of 10: 351/1000 = 35.10%
Accuracy of network on test set at epoch 9 of 10: 351/1000 = 35.10%
Accuracy of network on test set at epoch 10 of 10: 351/1000 = 35.10%
Training time: 17.5 seconds.
Training loss plot saved in /Plots.
Testing Accuracy plot saved in /Plots.
             building  barren land  trees  grassland  road  water
building            0            0      0          0     0      0
barren land         0            0      0          0     0      0
trees               0            0      0          0     0      0
grassland           0            0      0          0     0      0
road                0            0      0          0     0      0
water              38          235    190        160    26    351
Accuracy rate: 35.10%
Misclassifcation rate: 64.90%
Confusion matrix plot saved in /Plots.
ubuntu@ip-172-31-21-75:~/Final-Project-Group4/Code$ python3 network.py 
Sample image grid saved to /Plots with classes:
barren land, water, water, water, trees, water, grassland, barren land, barren land, water, road, trees, water, grassland, road, grassland, water, grassland, water, water, barren land, grassland, water, trees, building, trees, barren land, building, water, water, water, water, water, water, trees, grassland, trees, barren land, building, barren land, barren land, water, water, barren land, barren land, barren land, grassland, water, trees, water, water, trees, barren land, water, water, trees, road, water, water, water, water, road, water, grassland, trees, water, grassland, grassland, water, water, barren land, barren land, road, trees, water, trees, water, water, barren land, trees, water, barren land, barren land, trees, water, grassland, grassland, barren land, water, water, water, water, barren land, barren land, grassland, water, water, water, barren land, trees
NETWORK PARAMETERS:
Batch size: 100
Epochs: 10
Learning rate: 0.005000
Momentum: 0.950000
Weight Decay: 0.000500
Input channels: 4
Input dimensions: 28

NETWORK CONFIGURATION:
0 -> QuasiAlex (
  (conv1): Conv2d(4, 12, kernel_size=(11, 11), stride=(1, 1))
  (conv2): Conv2d(12, 32, kernel_size=(5, 5), stride=(1, 1))
  (conv3): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1))
  (conv4): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv5): Conv2d(48, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (pool): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))
  (fc1): Linear (1152 -> 24)
  (fc2): Linear (24 -> 24)
  (fc3): Linear (24 -> 6)
)
1 -> Conv2d(4, 12, kernel_size=(11, 11), stride=(1, 1))
2 -> Conv2d(12, 32, kernel_size=(5, 5), stride=(1, 1))
3 -> Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1))
4 -> Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
5 -> Conv2d(48, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
6 -> MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))
7 -> Linear (1152 -> 24)
8 -> Linear (24 -> 24)
9 -> Linear (24 -> 6)
Training loss at epoch 1 of 10, step 100 of 3240: 1.5044
Training loss at epoch 1 of 10, step 200 of 3240: 0.8992
Training loss at epoch 1 of 10, step 300 of 3240: 0.5368
Training loss at epoch 1 of 10, step 400 of 3240: 0.8769
Training loss at epoch 1 of 10, step 500 of 3240: 0.6756
Training loss at epoch 1 of 10, step 600 of 3240: 0.5333
Training loss at epoch 1 of 10, step 700 of 3240: 0.8996
Training loss at epoch 1 of 10, step 800 of 3240: 0.6603
Training loss at epoch 1 of 10, step 900 of 3240: 0.5137
Training loss at epoch 1 of 10, step 1000 of 3240: 0.4587
Training loss at epoch 1 of 10, step 1100 of 3240: 0.4394
Training loss at epoch 1 of 10, step 1200 of 3240: 0.6217
Training loss at epoch 1 of 10, step 1300 of 3240: 0.5155
Training loss at epoch 1 of 10, step 1400 of 3240: 0.5218
Training loss at epoch 1 of 10, step 1500 of 3240: 0.4118
Training loss at epoch 1 of 10, step 1600 of 3240: 0.2741
Training loss at epoch 1 of 10, step 1700 of 3240: 0.2615
Training loss at epoch 1 of 10, step 1800 of 3240: 0.2739
Training loss at epoch 1 of 10, step 1900 of 3240: 0.3624
Training loss at epoch 1 of 10, step 2000 of 3240: 0.3365
Training loss at epoch 1 of 10, step 2100 of 3240: 0.4281
Training loss at epoch 1 of 10, step 2200 of 3240: 0.2517
Training loss at epoch 1 of 10, step 2300 of 3240: 0.4883
Training loss at epoch 1 of 10, step 2400 of 3240: 0.3058
Training loss at epoch 1 of 10, step 2500 of 3240: 0.3018
Training loss at epoch 1 of 10, step 2600 of 3240: 0.4990
Training loss at epoch 1 of 10, step 2700 of 3240: 0.3338
Training loss at epoch 1 of 10, step 2800 of 3240: 0.2847
Training loss at epoch 1 of 10, step 2900 of 3240: 0.3088
Training loss at epoch 1 of 10, step 3000 of 3240: 0.3695
Training loss at epoch 1 of 10, step 3100 of 3240: 0.3454
Training loss at epoch 1 of 10, step 3200 of 3240: 0.3143
Accuracy of network on test set at epoch 1 of 10: 70009/81000 = 86.43%
Training loss at epoch 2 of 10, step 100 of 3240: 0.3887
Training loss at epoch 2 of 10, step 200 of 3240: 0.2998
Training loss at epoch 2 of 10, step 300 of 3240: 0.4029
Training loss at epoch 2 of 10, step 400 of 3240: 0.3425
Training loss at epoch 2 of 10, step 500 of 3240: 0.6648
Training loss at epoch 2 of 10, step 600 of 3240: 0.5000
Training loss at epoch 2 of 10, step 700 of 3240: 0.3436
Training loss at epoch 2 of 10, step 800 of 3240: 0.2777
Training loss at epoch 2 of 10, step 900 of 3240: 0.5181
Training loss at epoch 2 of 10, step 1000 of 3240: 0.3204
Training loss at epoch 2 of 10, step 1100 of 3240: 0.2031
Training loss at epoch 2 of 10, step 1200 of 3240: 0.2902
Training loss at epoch 2 of 10, step 1300 of 3240: 0.1996
Training loss at epoch 2 of 10, step 1400 of 3240: 0.2762
Training loss at epoch 2 of 10, step 1500 of 3240: 0.4050
Training loss at epoch 2 of 10, step 1600 of 3240: 0.2252
Training loss at epoch 2 of 10, step 1700 of 3240: 0.3708
Training loss at epoch 2 of 10, step 1800 of 3240: 0.3250
Training loss at epoch 2 of 10, step 1900 of 3240: 0.3307
Training loss at epoch 2 of 10, step 2000 of 3240: 0.2697
Training loss at epoch 2 of 10, step 2100 of 3240: 0.2839
Training loss at epoch 2 of 10, step 2200 of 3240: 0.4651
Training loss at epoch 2 of 10, step 2300 of 3240: 0.2799
Training loss at epoch 2 of 10, step 2400 of 3240: 0.3150
Training loss at epoch 2 of 10, step 2500 of 3240: 0.3058
Training loss at epoch 2 of 10, step 2600 of 3240: 0.5263
Training loss at epoch 2 of 10, step 2700 of 3240: 0.2395
Training loss at epoch 2 of 10, step 2800 of 3240: 0.2601
Training loss at epoch 2 of 10, step 2900 of 3240: 0.4002
Training loss at epoch 2 of 10, step 3000 of 3240: 0.2316
Training loss at epoch 2 of 10, step 3100 of 3240: 0.3757
Training loss at epoch 2 of 10, step 3200 of 3240: 0.1643
Accuracy of network on test set at epoch 2 of 10: 73968/81000 = 91.32%
Training loss at epoch 3 of 10, step 100 of 3240: 0.4367
Training loss at epoch 3 of 10, step 200 of 3240: 0.2505
Training loss at epoch 3 of 10, step 300 of 3240: 0.1067
Training loss at epoch 3 of 10, step 400 of 3240: 0.2665
Training loss at epoch 3 of 10, step 500 of 3240: 0.2187
Training loss at epoch 3 of 10, step 600 of 3240: 0.2623
Training loss at epoch 3 of 10, step 700 of 3240: 0.3085
Training loss at epoch 3 of 10, step 800 of 3240: 0.3893
Training loss at epoch 3 of 10, step 900 of 3240: 0.2290
Training loss at epoch 3 of 10, step 1000 of 3240: 0.2090
Training loss at epoch 3 of 10, step 1100 of 3240: 0.2835
Training loss at epoch 3 of 10, step 1200 of 3240: 0.1805
Training loss at epoch 3 of 10, step 1300 of 3240: 0.2439
Training loss at epoch 3 of 10, step 1400 of 3240: 0.1698
Training loss at epoch 3 of 10, step 1500 of 3240: 0.1795
Training loss at epoch 3 of 10, step 1600 of 3240: 0.3019
Training loss at epoch 3 of 10, step 1700 of 3240: 0.2448
Training loss at epoch 3 of 10, step 1800 of 3240: 0.1172
Training loss at epoch 3 of 10, step 1900 of 3240: 0.2978
Training loss at epoch 3 of 10, step 2000 of 3240: 0.1514
Training loss at epoch 3 of 10, step 2100 of 3240: 0.1393
Training loss at epoch 3 of 10, step 2200 of 3240: 0.4891
Training loss at epoch 3 of 10, step 2300 of 3240: 0.2945
Training loss at epoch 3 of 10, step 2400 of 3240: 0.2812
Training loss at epoch 3 of 10, step 2500 of 3240: 0.2604
Training loss at epoch 3 of 10, step 2600 of 3240: 0.2127
Training loss at epoch 3 of 10, step 2700 of 3240: 0.2448
Training loss at epoch 3 of 10, step 2800 of 3240: 0.1681
Training loss at epoch 3 of 10, step 2900 of 3240: 0.1173
Training loss at epoch 3 of 10, step 3000 of 3240: 0.1927
Training loss at epoch 3 of 10, step 3100 of 3240: 0.1438
Training loss at epoch 3 of 10, step 3200 of 3240: 0.0461
Accuracy of network on test set at epoch 3 of 10: 77031/81000 = 95.10%
Training loss at epoch 4 of 10, step 100 of 3240: 0.1188
Training loss at epoch 4 of 10, step 200 of 3240: 0.1244
Training loss at epoch 4 of 10, step 300 of 3240: 0.2589
Training loss at epoch 4 of 10, step 400 of 3240: 0.1495
Training loss at epoch 4 of 10, step 500 of 3240: 0.1055
Training loss at epoch 4 of 10, step 600 of 3240: 0.1897
Training loss at epoch 4 of 10, step 700 of 3240: 0.1215
Training loss at epoch 4 of 10, step 800 of 3240: 0.1169
Training loss at epoch 4 of 10, step 900 of 3240: 0.0829
Training loss at epoch 4 of 10, step 1000 of 3240: 0.1734
Training loss at epoch 4 of 10, step 1100 of 3240: 0.1050
Training loss at epoch 4 of 10, step 1200 of 3240: 0.0463
Training loss at epoch 4 of 10, step 1300 of 3240: 0.2479
Training loss at epoch 4 of 10, step 1400 of 3240: 0.1957
Training loss at epoch 4 of 10, step 1500 of 3240: 0.1886
Training loss at epoch 4 of 10, step 1600 of 3240: 0.1166
Training loss at epoch 4 of 10, step 1700 of 3240: 0.1869
Training loss at epoch 4 of 10, step 1800 of 3240: 0.1466
Training loss at epoch 4 of 10, step 1900 of 3240: 0.1368
Training loss at epoch 4 of 10, step 2000 of 3240: 0.0882
Training loss at epoch 4 of 10, step 2100 of 3240: 0.1454
Training loss at epoch 4 of 10, step 2200 of 3240: 0.0569
Training loss at epoch 4 of 10, step 2300 of 3240: 0.1416
Training loss at epoch 4 of 10, step 2400 of 3240: 0.1003
Training loss at epoch 4 of 10, step 2500 of 3240: 0.1702
Training loss at epoch 4 of 10, step 2600 of 3240: 0.0809
Training loss at epoch 4 of 10, step 2700 of 3240: 0.1219
Training loss at epoch 4 of 10, step 2800 of 3240: 0.1094
Training loss at epoch 4 of 10, step 2900 of 3240: 0.1110
Training loss at epoch 4 of 10, step 3000 of 3240: 0.1645
Training loss at epoch 4 of 10, step 3100 of 3240: 0.0798
Training loss at epoch 4 of 10, step 3200 of 3240: 0.0682
Accuracy of network on test set at epoch 4 of 10: 78145/81000 = 96.48%
Training loss at epoch 5 of 10, step 100 of 3240: 0.0952
Training loss at epoch 5 of 10, step 200 of 3240: 0.1296
Training loss at epoch 5 of 10, step 300 of 3240: 0.1378
Training loss at epoch 5 of 10, step 400 of 3240: 0.1343
Training loss at epoch 5 of 10, step 500 of 3240: 0.1109
Training loss at epoch 5 of 10, step 600 of 3240: 0.0825
Training loss at epoch 5 of 10, step 700 of 3240: 0.1723
Training loss at epoch 5 of 10, step 800 of 3240: 0.0916
Training loss at epoch 5 of 10, step 900 of 3240: 0.1330
Training loss at epoch 5 of 10, step 1000 of 3240: 0.1667
Training loss at epoch 5 of 10, step 1100 of 3240: 0.2357
Training loss at epoch 5 of 10, step 1200 of 3240: 0.0562
Training loss at epoch 5 of 10, step 1300 of 3240: 0.1208
Training loss at epoch 5 of 10, step 1400 of 3240: 0.1601
Training loss at epoch 5 of 10, step 1500 of 3240: 0.0614
Training loss at epoch 5 of 10, step 1600 of 3240: 0.0614
Training loss at epoch 5 of 10, step 1700 of 3240: 0.1128
Training loss at epoch 5 of 10, step 1800 of 3240: 0.0790
Training loss at epoch 5 of 10, step 1900 of 3240: 0.1994
Training loss at epoch 5 of 10, step 2000 of 3240: 0.0839
Training loss at epoch 5 of 10, step 2100 of 3240: 0.0705
Training loss at epoch 5 of 10, step 2200 of 3240: 0.1020
Training loss at epoch 5 of 10, step 2300 of 3240: 0.1096
Training loss at epoch 5 of 10, step 2400 of 3240: 0.0690
Training loss at epoch 5 of 10, step 2500 of 3240: 0.0915
Training loss at epoch 5 of 10, step 2600 of 3240: 0.0428
Training loss at epoch 5 of 10, step 2700 of 3240: 0.0883
Training loss at epoch 5 of 10, step 2800 of 3240: 0.0810
Training loss at epoch 5 of 10, step 2900 of 3240: 0.1591
Training loss at epoch 5 of 10, step 3000 of 3240: 0.0600
Training loss at epoch 5 of 10, step 3100 of 3240: 0.0833
Training loss at epoch 5 of 10, step 3200 of 3240: 0.1248
Accuracy of network on test set at epoch 5 of 10: 77573/81000 = 95.77%
Training loss at epoch 6 of 10, step 100 of 3240: 0.0957
Training loss at epoch 6 of 10, step 200 of 3240: 0.1299
Training loss at epoch 6 of 10, step 300 of 3240: 0.1287
Training loss at epoch 6 of 10, step 400 of 3240: 0.0519
Training loss at epoch 6 of 10, step 500 of 3240: 0.0557
Training loss at epoch 6 of 10, step 600 of 3240: 0.1196
Training loss at epoch 6 of 10, step 700 of 3240: 0.1546
Training loss at epoch 6 of 10, step 800 of 3240: 0.0970
Training loss at epoch 6 of 10, step 900 of 3240: 0.0613
Training loss at epoch 6 of 10, step 1000 of 3240: 0.0689
Training loss at epoch 6 of 10, step 1100 of 3240: 0.0704
Training loss at epoch 6 of 10, step 1200 of 3240: 0.0901
Training loss at epoch 6 of 10, step 1300 of 3240: 0.1668
Training loss at epoch 6 of 10, step 1400 of 3240: 0.1859
Training loss at epoch 6 of 10, step 1500 of 3240: 0.0462
Training loss at epoch 6 of 10, step 1600 of 3240: 0.0936
Training loss at epoch 6 of 10, step 1700 of 3240: 0.1017
Training loss at epoch 6 of 10, step 1800 of 3240: 0.1373
Training loss at epoch 6 of 10, step 1900 of 3240: 0.1891
Training loss at epoch 6 of 10, step 2000 of 3240: 0.1543
Training loss at epoch 6 of 10, step 2100 of 3240: 0.0761
Training loss at epoch 6 of 10, step 2200 of 3240: 0.0630
Training loss at epoch 6 of 10, step 2300 of 3240: 0.1001
Training loss at epoch 6 of 10, step 2400 of 3240: 0.0350
Training loss at epoch 6 of 10, step 2500 of 3240: 0.0581
Training loss at epoch 6 of 10, step 2600 of 3240: 0.0662
Training loss at epoch 6 of 10, step 2700 of 3240: 0.0878
Training loss at epoch 6 of 10, step 2800 of 3240: 0.0603
Training loss at epoch 6 of 10, step 2900 of 3240: 0.0653
Training loss at epoch 6 of 10, step 3000 of 3240: 0.1478
Training loss at epoch 6 of 10, step 3100 of 3240: 0.2125
Training loss at epoch 6 of 10, step 3200 of 3240: 0.0659
Accuracy of network on test set at epoch 6 of 10: 76643/81000 = 94.62%
Training loss at epoch 7 of 10, step 100 of 3240: 0.2045
Training loss at epoch 7 of 10, step 200 of 3240: 0.0693
Training loss at epoch 7 of 10, step 300 of 3240: 0.0583
Training loss at epoch 7 of 10, step 400 of 3240: 0.0933
Training loss at epoch 7 of 10, step 500 of 3240: 0.0534
Training loss at epoch 7 of 10, step 600 of 3240: 0.0370
Training loss at epoch 7 of 10, step 700 of 3240: 0.0883
Training loss at epoch 7 of 10, step 800 of 3240: 0.1529
Training loss at epoch 7 of 10, step 900 of 3240: 0.1306
Training loss at epoch 7 of 10, step 1000 of 3240: 0.2618
Training loss at epoch 7 of 10, step 1100 of 3240: 0.2355
Training loss at epoch 7 of 10, step 1200 of 3240: 0.2430
Training loss at epoch 7 of 10, step 1300 of 3240: 0.0801
Training loss at epoch 7 of 10, step 1400 of 3240: 0.1433
Training loss at epoch 7 of 10, step 1500 of 3240: 0.0969
Training loss at epoch 7 of 10, step 1600 of 3240: 0.0593
Training loss at epoch 7 of 10, step 1700 of 3240: 0.1244
Training loss at epoch 7 of 10, step 1800 of 3240: 0.1019
Training loss at epoch 7 of 10, step 1900 of 3240: 0.0791
Training loss at epoch 7 of 10, step 2000 of 3240: 0.0858
Training loss at epoch 7 of 10, step 2100 of 3240: 0.0780
Training loss at epoch 7 of 10, step 2200 of 3240: 0.0523
Training loss at epoch 7 of 10, step 2300 of 3240: 0.0638
Training loss at epoch 7 of 10, step 2400 of 3240: 0.0912
Training loss at epoch 7 of 10, step 2500 of 3240: 0.0829
Training loss at epoch 7 of 10, step 2600 of 3240: 0.1515
Training loss at epoch 7 of 10, step 2700 of 3240: 0.1099
Training loss at epoch 7 of 10, step 2800 of 3240: 0.0754
Training loss at epoch 7 of 10, step 2900 of 3240: 0.0330
Training loss at epoch 7 of 10, step 3000 of 3240: 0.2261
Training loss at epoch 7 of 10, step 3100 of 3240: 0.1084
Training loss at epoch 7 of 10, step 3200 of 3240: 0.1295
Accuracy of network on test set at epoch 7 of 10: 77896/81000 = 96.17%
Training loss at epoch 8 of 10, step 100 of 3240: 0.0919
Training loss at epoch 8 of 10, step 200 of 3240: 0.0384
Training loss at epoch 8 of 10, step 300 of 3240: 0.0811
Training loss at epoch 8 of 10, step 400 of 3240: 0.1702
Training loss at epoch 8 of 10, step 500 of 3240: 0.0582
Training loss at epoch 8 of 10, step 600 of 3240: 0.1620
Training loss at epoch 8 of 10, step 700 of 3240: 0.1162
Training loss at epoch 8 of 10, step 800 of 3240: 0.1124
Training loss at epoch 8 of 10, step 900 of 3240: 0.0493
Training loss at epoch 8 of 10, step 1000 of 3240: 0.1446
Training loss at epoch 8 of 10, step 1100 of 3240: 0.0803
Training loss at epoch 8 of 10, step 1200 of 3240: 0.0648
Training loss at epoch 8 of 10, step 1300 of 3240: 0.0903
Training loss at epoch 8 of 10, step 1400 of 3240: 0.0726
Training loss at epoch 8 of 10, step 1500 of 3240: 0.0600
Training loss at epoch 8 of 10, step 1600 of 3240: 0.0701
Training loss at epoch 8 of 10, step 1700 of 3240: 0.0860
Training loss at epoch 8 of 10, step 1800 of 3240: 0.0504
Training loss at epoch 8 of 10, step 1900 of 3240: 0.0366
Training loss at epoch 8 of 10, step 2000 of 3240: 0.0545
Training loss at epoch 8 of 10, step 2100 of 3240: 0.0757
Training loss at epoch 8 of 10, step 2200 of 3240: 0.1182
Training loss at epoch 8 of 10, step 2300 of 3240: 0.1022
Training loss at epoch 8 of 10, step 2400 of 3240: 0.1880
Training loss at epoch 8 of 10, step 2500 of 3240: 0.1522
Training loss at epoch 8 of 10, step 2600 of 3240: 0.0496
Training loss at epoch 8 of 10, step 2700 of 3240: 0.1080
Training loss at epoch 8 of 10, step 2800 of 3240: 0.0413
Training loss at epoch 8 of 10, step 2900 of 3240: 0.1774
Training loss at epoch 8 of 10, step 3000 of 3240: 0.0692
Training loss at epoch 8 of 10, step 3100 of 3240: 0.1072
Training loss at epoch 8 of 10, step 3200 of 3240: 0.1626
Accuracy of network on test set at epoch 8 of 10: 78711/81000 = 97.17%
Training loss at epoch 9 of 10, step 100 of 3240: 0.0870
Training loss at epoch 9 of 10, step 200 of 3240: 0.0450
Training loss at epoch 9 of 10, step 300 of 3240: 0.0529
Training loss at epoch 9 of 10, step 400 of 3240: 0.0398
Training loss at epoch 9 of 10, step 500 of 3240: 0.0889
Training loss at epoch 9 of 10, step 600 of 3240: 0.0620
Training loss at epoch 9 of 10, step 700 of 3240: 0.1152
Training loss at epoch 9 of 10, step 800 of 3240: 0.1208
Training loss at epoch 9 of 10, step 900 of 3240: 0.0738
Training loss at epoch 9 of 10, step 1000 of 3240: 0.0726
Training loss at epoch 9 of 10, step 1100 of 3240: 0.0892
Training loss at epoch 9 of 10, step 1200 of 3240: 0.0645
Training loss at epoch 9 of 10, step 1300 of 3240: 0.0608
Training loss at epoch 9 of 10, step 1400 of 3240: 0.1023
Training loss at epoch 9 of 10, step 1500 of 3240: 0.0750
Training loss at epoch 9 of 10, step 1600 of 3240: 0.0767
Training loss at epoch 9 of 10, step 1700 of 3240: 0.0740
Training loss at epoch 9 of 10, step 1800 of 3240: 0.1787
Training loss at epoch 9 of 10, step 1900 of 3240: 0.0640
Training loss at epoch 9 of 10, step 2000 of 3240: 0.0585
Training loss at epoch 9 of 10, step 2100 of 3240: 0.0731
Training loss at epoch 9 of 10, step 2200 of 3240: 0.0623
Training loss at epoch 9 of 10, step 2300 of 3240: 0.0643
Training loss at epoch 9 of 10, step 2400 of 3240: 0.0702
Training loss at epoch 9 of 10, step 2500 of 3240: 0.1362
Training loss at epoch 9 of 10, step 2600 of 3240: 0.1042
Training loss at epoch 9 of 10, step 2700 of 3240: 0.1721
Training loss at epoch 9 of 10, step 2800 of 3240: 0.2511
Training loss at epoch 9 of 10, step 2900 of 3240: 0.0335
Training loss at epoch 9 of 10, step 3000 of 3240: 0.1257
Training loss at epoch 9 of 10, step 3100 of 3240: 0.0978
Training loss at epoch 9 of 10, step 3200 of 3240: 0.1099
Accuracy of network on test set at epoch 9 of 10: 78986/81000 = 97.51%
Training loss at epoch 10 of 10, step 100 of 3240: 0.0591
Training loss at epoch 10 of 10, step 200 of 3240: 0.0689
Training loss at epoch 10 of 10, step 300 of 3240: 0.1141
Training loss at epoch 10 of 10, step 400 of 3240: 0.0761
Training loss at epoch 10 of 10, step 500 of 3240: 0.1383
Training loss at epoch 10 of 10, step 600 of 3240: 0.1466
Training loss at epoch 10 of 10, step 700 of 3240: 0.0464
Training loss at epoch 10 of 10, step 800 of 3240: 0.0503
Training loss at epoch 10 of 10, step 900 of 3240: 0.0801
Training loss at epoch 10 of 10, step 1000 of 3240: 0.0738
Training loss at epoch 10 of 10, step 1100 of 3240: 0.0339
Training loss at epoch 10 of 10, step 1200 of 3240: 0.1275
Training loss at epoch 10 of 10, step 1300 of 3240: 0.1295
Training loss at epoch 10 of 10, step 1400 of 3240: 0.0409
Training loss at epoch 10 of 10, step 1500 of 3240: 0.0445
Training loss at epoch 10 of 10, step 1600 of 3240: 0.0920
Training loss at epoch 10 of 10, step 1700 of 3240: 0.1494
Training loss at epoch 10 of 10, step 1800 of 3240: 0.1261
Training loss at epoch 10 of 10, step 1900 of 3240: 0.0599
Training loss at epoch 10 of 10, step 2000 of 3240: 0.0291
Training loss at epoch 10 of 10, step 2100 of 3240: 0.0562
Training loss at epoch 10 of 10, step 2200 of 3240: 0.0283
Training loss at epoch 10 of 10, step 2300 of 3240: 0.0294
Training loss at epoch 10 of 10, step 2400 of 3240: 0.0605
Training loss at epoch 10 of 10, step 2500 of 3240: 0.0736
Training loss at epoch 10 of 10, step 2600 of 3240: 0.0484
Training loss at epoch 10 of 10, step 2700 of 3240: 0.0404
Training loss at epoch 10 of 10, step 2800 of 3240: 0.0866
Training loss at epoch 10 of 10, step 2900 of 3240: 0.1033
Training loss at epoch 10 of 10, step 3000 of 3240: 0.1137
Training loss at epoch 10 of 10, step 3100 of 3240: 0.0566
Training loss at epoch 10 of 10, step 3200 of 3240: 0.1234
Accuracy of network on test set at epoch 10 of 10: 78377/81000 = 96.76%
Training time: 3350.1 seconds.
Training loss plot saved in /Plots.
Testing Accuracy plot saved in /Plots.
             building  barren land  trees  grassland  road  water
building         3625            7      3          0   204     22
barren land         0        18079     11       1192     4      0
trees               0            3  13513         78     5      0
grassland           0          272    649      11323     0      0
road               89            6      9          3  1854     63
water               0            0      0          0     3  29983
Accuracy rate: 96.76%
Misclassifcation rate: 3.24%
Confusion matrix plot saved in /Plots.
