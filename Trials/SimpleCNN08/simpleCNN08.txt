Sample image grid saved to /Plots with classes:
water, grassland, trees, barren land, trees, water, trees, barren land, water, water, grassland, water, building, water, water, barren land, trees, barren land, water, water, water, barren land, barren land, water, trees, water, water, barren land, grassland, grassland, grassland, trees, water, trees, water, water, grassland, barren land, grassland, grassland, water, trees, water, water, water, trees, barren land, water, water, barren land, barren land, barren land, barren land, building, water, barren land, road, barren land, barren land, water, trees, barren land, trees, water, water, barren land, barren land, grassland, water, water, water, trees, barren land, barren land, grassland, road, road, building, barren land, barren land, water, water, barren land, barren land, water, barren land, building, road, building, barren land, water, water, water, grassland, grassland, water, water, water, water, barren land
NETWORK PARAMETERS:
Batch size: 100
Epochs: 10
Learning rate: 0.005000
Input channels: 4
Input dimensions: 28
Conv kernel size: 4    
NETWORK CONFIGURATION:
0 -> SimpleCNN (
  (conv1): Conv2d(4, 16, kernel_size=(4, 4), stride=(1, 1))
  (pool): MaxPool2d (size=(3, 3), stride=(2, 2), dilation=(1, 1))
  (fc1): Linear (2304 -> 6)
)
1 -> Conv2d(4, 16, kernel_size=(4, 4), stride=(1, 1))
2 -> MaxPool2d (size=(3, 3), stride=(2, 2), dilation=(1, 1))
3 -> Linear (2304 -> 6)
Training loss at epoch 1 of 10, step 100 of 3240: 0.8070
Training loss at epoch 1 of 10, step 200 of 3240: 0.5869
Training loss at epoch 1 of 10, step 300 of 3240: 0.5392
Training loss at epoch 1 of 10, step 400 of 3240: 0.4620
Training loss at epoch 1 of 10, step 500 of 3240: 0.3982
Training loss at epoch 1 of 10, step 600 of 3240: 0.3750
Training loss at epoch 1 of 10, step 700 of 3240: 0.2874
Training loss at epoch 1 of 10, step 800 of 3240: 0.2360
Training loss at epoch 1 of 10, step 900 of 3240: 0.3584
Training loss at epoch 1 of 10, step 1000 of 3240: 0.2679
Training loss at epoch 1 of 10, step 1100 of 3240: 0.2729
Training loss at epoch 1 of 10, step 1200 of 3240: 0.3174
Training loss at epoch 1 of 10, step 1300 of 3240: 0.1964
Training loss at epoch 1 of 10, step 1400 of 3240: 0.1792
Training loss at epoch 1 of 10, step 1500 of 3240: 0.1812
Training loss at epoch 1 of 10, step 1600 of 3240: 0.1887
Training loss at epoch 1 of 10, step 1700 of 3240: 0.1718
Training loss at epoch 1 of 10, step 1800 of 3240: 0.1959
Training loss at epoch 1 of 10, step 1900 of 3240: 0.1246
Training loss at epoch 1 of 10, step 2000 of 3240: 0.1848
Training loss at epoch 1 of 10, step 2100 of 3240: 0.2184
Training loss at epoch 1 of 10, step 2200 of 3240: 0.1382
Training loss at epoch 1 of 10, step 2300 of 3240: 0.1654
Training loss at epoch 1 of 10, step 2400 of 3240: 0.1723
Training loss at epoch 1 of 10, step 2500 of 3240: 0.1248
Training loss at epoch 1 of 10, step 2600 of 3240: 0.1848
Training loss at epoch 1 of 10, step 2700 of 3240: 0.1290
Training loss at epoch 1 of 10, step 2800 of 3240: 0.1733
Training loss at epoch 1 of 10, step 2900 of 3240: 0.1504
Training loss at epoch 1 of 10, step 3000 of 3240: 0.1362
Training loss at epoch 1 of 10, step 3100 of 3240: 0.1364
Training loss at epoch 1 of 10, step 3200 of 3240: 0.1578
Accuracy of network on test set at epoch 1 of 10: 76304/81000 = 94.20%
Training loss at epoch 2 of 10, step 100 of 3240: 0.1179
Training loss at epoch 2 of 10, step 200 of 3240: 0.2025
Training loss at epoch 2 of 10, step 300 of 3240: 0.0927
Training loss at epoch 2 of 10, step 400 of 3240: 0.1044
Training loss at epoch 2 of 10, step 500 of 3240: 0.1672
Training loss at epoch 2 of 10, step 600 of 3240: 0.1205
Training loss at epoch 2 of 10, step 700 of 3240: 0.2871
Training loss at epoch 2 of 10, step 800 of 3240: 0.1686
Training loss at epoch 2 of 10, step 900 of 3240: 0.1270
Training loss at epoch 2 of 10, step 1000 of 3240: 0.1626
Training loss at epoch 2 of 10, step 1100 of 3240: 0.2238
Training loss at epoch 2 of 10, step 1200 of 3240: 0.1398
Training loss at epoch 2 of 10, step 1300 of 3240: 0.1434
Training loss at epoch 2 of 10, step 1400 of 3240: 0.1254
Training loss at epoch 2 of 10, step 1500 of 3240: 0.1315
Training loss at epoch 2 of 10, step 1600 of 3240: 0.1537
Training loss at epoch 2 of 10, step 1700 of 3240: 0.1723
Training loss at epoch 2 of 10, step 1800 of 3240: 0.1556
Training loss at epoch 2 of 10, step 1900 of 3240: 0.1532
Training loss at epoch 2 of 10, step 2000 of 3240: 0.0818
Training loss at epoch 2 of 10, step 2100 of 3240: 0.1598
Training loss at epoch 2 of 10, step 2200 of 3240: 0.1206
Training loss at epoch 2 of 10, step 2300 of 3240: 0.0800
Training loss at epoch 2 of 10, step 2400 of 3240: 0.1701
Training loss at epoch 2 of 10, step 2500 of 3240: 0.1985
Training loss at epoch 2 of 10, step 2600 of 3240: 0.2475
Training loss at epoch 2 of 10, step 2700 of 3240: 0.1005
Training loss at epoch 2 of 10, step 2800 of 3240: 0.2092
Training loss at epoch 2 of 10, step 2900 of 3240: 0.1314
Training loss at epoch 2 of 10, step 3000 of 3240: 0.0892
Training loss at epoch 2 of 10, step 3100 of 3240: 0.1032
Training loss at epoch 2 of 10, step 3200 of 3240: 0.0415
Accuracy of network on test set at epoch 2 of 10: 77732/81000 = 95.97%
Training loss at epoch 3 of 10, step 100 of 3240: 0.0841
Training loss at epoch 3 of 10, step 200 of 3240: 0.1033
Training loss at epoch 3 of 10, step 300 of 3240: 0.1276
Training loss at epoch 3 of 10, step 400 of 3240: 0.0852
Training loss at epoch 3 of 10, step 500 of 3240: 0.2296
Training loss at epoch 3 of 10, step 600 of 3240: 0.1583
Training loss at epoch 3 of 10, step 700 of 3240: 0.1022
Training loss at epoch 3 of 10, step 800 of 3240: 0.1410
Training loss at epoch 3 of 10, step 900 of 3240: 0.2030
Training loss at epoch 3 of 10, step 1000 of 3240: 0.0852
Training loss at epoch 3 of 10, step 1100 of 3240: 0.1520
Training loss at epoch 3 of 10, step 1200 of 3240: 0.0884
Training loss at epoch 3 of 10, step 1300 of 3240: 0.1004
Training loss at epoch 3 of 10, step 1400 of 3240: 0.1365
Training loss at epoch 3 of 10, step 1500 of 3240: 0.1461
Training loss at epoch 3 of 10, step 1600 of 3240: 0.0627
Training loss at epoch 3 of 10, step 1700 of 3240: 0.0981
Training loss at epoch 3 of 10, step 1800 of 3240: 0.0835
Training loss at epoch 3 of 10, step 1900 of 3240: 0.0733
Training loss at epoch 3 of 10, step 2000 of 3240: 0.1531
Training loss at epoch 3 of 10, step 2100 of 3240: 0.1364
Training loss at epoch 3 of 10, step 2200 of 3240: 0.0705
Training loss at epoch 3 of 10, step 2300 of 3240: 0.1486
Training loss at epoch 3 of 10, step 2400 of 3240: 0.0981
Training loss at epoch 3 of 10, step 2500 of 3240: 0.1001
Training loss at epoch 3 of 10, step 2600 of 3240: 0.0671
Training loss at epoch 3 of 10, step 2700 of 3240: 0.1034
Training loss at epoch 3 of 10, step 2800 of 3240: 0.0663
Training loss at epoch 3 of 10, step 2900 of 3240: 0.1021
Training loss at epoch 3 of 10, step 3000 of 3240: 0.1497
Training loss at epoch 3 of 10, step 3100 of 3240: 0.0735
Training loss at epoch 3 of 10, step 3200 of 3240: 0.1039
Accuracy of network on test set at epoch 3 of 10: 78440/81000 = 96.84%
Training loss at epoch 4 of 10, step 100 of 3240: 0.0820
Training loss at epoch 4 of 10, step 200 of 3240: 0.1111
Training loss at epoch 4 of 10, step 300 of 3240: 0.0505
Training loss at epoch 4 of 10, step 400 of 3240: 0.0855
Training loss at epoch 4 of 10, step 500 of 3240: 0.0822
Training loss at epoch 4 of 10, step 600 of 3240: 0.1093
Training loss at epoch 4 of 10, step 700 of 3240: 0.1285
Training loss at epoch 4 of 10, step 800 of 3240: 0.0598
Training loss at epoch 4 of 10, step 900 of 3240: 0.1084
Training loss at epoch 4 of 10, step 1000 of 3240: 0.1808
Training loss at epoch 4 of 10, step 1100 of 3240: 0.1273
Training loss at epoch 4 of 10, step 1200 of 3240: 0.0858
Training loss at epoch 4 of 10, step 1300 of 3240: 0.0870
Training loss at epoch 4 of 10, step 1400 of 3240: 0.0892
Training loss at epoch 4 of 10, step 1500 of 3240: 0.0824
Training loss at epoch 4 of 10, step 1600 of 3240: 0.0769
Training loss at epoch 4 of 10, step 1700 of 3240: 0.0576
Training loss at epoch 4 of 10, step 1800 of 3240: 0.0613
Training loss at epoch 4 of 10, step 1900 of 3240: 0.1007
Training loss at epoch 4 of 10, step 2000 of 3240: 0.0485
Training loss at epoch 4 of 10, step 2100 of 3240: 0.0957
Training loss at epoch 4 of 10, step 2200 of 3240: 0.0941
Training loss at epoch 4 of 10, step 2300 of 3240: 0.0872
Training loss at epoch 4 of 10, step 2400 of 3240: 0.0408
Training loss at epoch 4 of 10, step 2500 of 3240: 0.0634
Training loss at epoch 4 of 10, step 2600 of 3240: 0.1158
Training loss at epoch 4 of 10, step 2700 of 3240: 0.0769
Training loss at epoch 4 of 10, step 2800 of 3240: 0.1395
Training loss at epoch 4 of 10, step 2900 of 3240: 0.0606
Training loss at epoch 4 of 10, step 3000 of 3240: 0.1177
Training loss at epoch 4 of 10, step 3100 of 3240: 0.0633
Training loss at epoch 4 of 10, step 3200 of 3240: 0.1361
Accuracy of network on test set at epoch 4 of 10: 78735/81000 = 97.20%
Training loss at epoch 5 of 10, step 100 of 3240: 0.0954
Training loss at epoch 5 of 10, step 200 of 3240: 0.0937
Training loss at epoch 5 of 10, step 300 of 3240: 0.0831
Training loss at epoch 5 of 10, step 400 of 3240: 0.1127
Training loss at epoch 5 of 10, step 500 of 3240: 0.0965
Training loss at epoch 5 of 10, step 600 of 3240: 0.0813
Training loss at epoch 5 of 10, step 700 of 3240: 0.0688
Training loss at epoch 5 of 10, step 800 of 3240: 0.0909
Training loss at epoch 5 of 10, step 900 of 3240: 0.0428
Training loss at epoch 5 of 10, step 1000 of 3240: 0.0683
Training loss at epoch 5 of 10, step 1100 of 3240: 0.0651
Training loss at epoch 5 of 10, step 1200 of 3240: 0.0476
Training loss at epoch 5 of 10, step 1300 of 3240: 0.0644
Training loss at epoch 5 of 10, step 1400 of 3240: 0.0521
Training loss at epoch 5 of 10, step 1500 of 3240: 0.1119
Training loss at epoch 5 of 10, step 1600 of 3240: 0.0592
Training loss at epoch 5 of 10, step 1700 of 3240: 0.1635
Training loss at epoch 5 of 10, step 1800 of 3240: 0.0525
Training loss at epoch 5 of 10, step 1900 of 3240: 0.0591
Training loss at epoch 5 of 10, step 2000 of 3240: 0.1384
Training loss at epoch 5 of 10, step 2100 of 3240: 0.1152
Training loss at epoch 5 of 10, step 2200 of 3240: 0.1076
Training loss at epoch 5 of 10, step 2300 of 3240: 0.0585
Training loss at epoch 5 of 10, step 2400 of 3240: 0.0539
Training loss at epoch 5 of 10, step 2500 of 3240: 0.0921
Training loss at epoch 5 of 10, step 2600 of 3240: 0.0521
Training loss at epoch 5 of 10, step 2700 of 3240: 0.0973
Training loss at epoch 5 of 10, step 2800 of 3240: 0.1262
Training loss at epoch 5 of 10, step 2900 of 3240: 0.0477
Training loss at epoch 5 of 10, step 3000 of 3240: 0.0515
Training loss at epoch 5 of 10, step 3100 of 3240: 0.0450
Training loss at epoch 5 of 10, step 3200 of 3240: 0.0783
Accuracy of network on test set at epoch 5 of 10: 78697/81000 = 97.16%
Training loss at epoch 6 of 10, step 100 of 3240: 0.1136
Training loss at epoch 6 of 10, step 200 of 3240: 0.0896
Training loss at epoch 6 of 10, step 300 of 3240: 0.0727
Training loss at epoch 6 of 10, step 400 of 3240: 0.0941
Training loss at epoch 6 of 10, step 500 of 3240: 0.0766
Training loss at epoch 6 of 10, step 600 of 3240: 0.0937
Training loss at epoch 6 of 10, step 700 of 3240: 0.0544
Training loss at epoch 6 of 10, step 800 of 3240: 0.0861
Training loss at epoch 6 of 10, step 900 of 3240: 0.0684
Training loss at epoch 6 of 10, step 1000 of 3240: 0.0353
Training loss at epoch 6 of 10, step 1100 of 3240: 0.0571
Training loss at epoch 6 of 10, step 1200 of 3240: 0.0967
Training loss at epoch 6 of 10, step 1300 of 3240: 0.0459
Training loss at epoch 6 of 10, step 1400 of 3240: 0.1135
Training loss at epoch 6 of 10, step 1500 of 3240: 0.1358
Training loss at epoch 6 of 10, step 1600 of 3240: 0.0751
Training loss at epoch 6 of 10, step 1700 of 3240: 0.0624
Training loss at epoch 6 of 10, step 1800 of 3240: 0.1112
Training loss at epoch 6 of 10, step 1900 of 3240: 0.0961
Training loss at epoch 6 of 10, step 2000 of 3240: 0.1121
Training loss at epoch 6 of 10, step 2100 of 3240: 0.0852
Training loss at epoch 6 of 10, step 2200 of 3240: 0.0771
Training loss at epoch 6 of 10, step 2300 of 3240: 0.1444
Training loss at epoch 6 of 10, step 2400 of 3240: 0.0346
Training loss at epoch 6 of 10, step 2500 of 3240: 0.0835
Training loss at epoch 6 of 10, step 2600 of 3240: 0.1173
Training loss at epoch 6 of 10, step 2700 of 3240: 0.1900
Training loss at epoch 6 of 10, step 2800 of 3240: 0.0556
Training loss at epoch 6 of 10, step 2900 of 3240: 0.0894
Training loss at epoch 6 of 10, step 3000 of 3240: 0.0991
Training loss at epoch 6 of 10, step 3100 of 3240: 0.1008
Training loss at epoch 6 of 10, step 3200 of 3240: 0.1027
Accuracy of network on test set at epoch 6 of 10: 78282/81000 = 96.64%
Training loss at epoch 7 of 10, step 100 of 3240: 0.0953
Training loss at epoch 7 of 10, step 200 of 3240: 0.0704
Training loss at epoch 7 of 10, step 300 of 3240: 0.1210
Training loss at epoch 7 of 10, step 400 of 3240: 0.0973
Training loss at epoch 7 of 10, step 500 of 3240: 0.0734
Training loss at epoch 7 of 10, step 600 of 3240: 0.0944
Training loss at epoch 7 of 10, step 700 of 3240: 0.0578
Training loss at epoch 7 of 10, step 800 of 3240: 0.0879
Training loss at epoch 7 of 10, step 900 of 3240: 0.1431
Training loss at epoch 7 of 10, step 1000 of 3240: 0.1699
Training loss at epoch 7 of 10, step 1100 of 3240: 0.0513
Training loss at epoch 7 of 10, step 1200 of 3240: 0.0561
Training loss at epoch 7 of 10, step 1300 of 3240: 0.0535
Training loss at epoch 7 of 10, step 1400 of 3240: 0.1097
Training loss at epoch 7 of 10, step 1500 of 3240: 0.1623
Training loss at epoch 7 of 10, step 1600 of 3240: 0.0541
Training loss at epoch 7 of 10, step 1700 of 3240: 0.0277
Training loss at epoch 7 of 10, step 1800 of 3240: 0.0614
Training loss at epoch 7 of 10, step 1900 of 3240: 0.0472
Training loss at epoch 7 of 10, step 2000 of 3240: 0.0631
Training loss at epoch 7 of 10, step 2100 of 3240: 0.1457
Training loss at epoch 7 of 10, step 2200 of 3240: 0.0842
Training loss at epoch 7 of 10, step 2300 of 3240: 0.1140
Training loss at epoch 7 of 10, step 2400 of 3240: 0.0961
Training loss at epoch 7 of 10, step 2500 of 3240: 0.0562
Training loss at epoch 7 of 10, step 2600 of 3240: 0.0684
Training loss at epoch 7 of 10, step 2700 of 3240: 0.0546
Training loss at epoch 7 of 10, step 2800 of 3240: 0.0798
Training loss at epoch 7 of 10, step 2900 of 3240: 0.0524
Training loss at epoch 7 of 10, step 3000 of 3240: 0.0421
Training loss at epoch 7 of 10, step 3100 of 3240: 0.0550
Training loss at epoch 7 of 10, step 3200 of 3240: 0.0370
Accuracy of network on test set at epoch 7 of 10: 78821/81000 = 97.31%
Training loss at epoch 8 of 10, step 100 of 3240: 0.0912
Training loss at epoch 8 of 10, step 200 of 3240: 0.0485
Training loss at epoch 8 of 10, step 300 of 3240: 0.1139
Training loss at epoch 8 of 10, step 400 of 3240: 0.1383
Training loss at epoch 8 of 10, step 500 of 3240: 0.1483
Training loss at epoch 8 of 10, step 600 of 3240: 0.0678
Training loss at epoch 8 of 10, step 700 of 3240: 0.0547
Training loss at epoch 8 of 10, step 800 of 3240: 0.0721
Training loss at epoch 8 of 10, step 900 of 3240: 0.0809
Training loss at epoch 8 of 10, step 1000 of 3240: 0.1334
Training loss at epoch 8 of 10, step 1100 of 3240: 0.0358
Training loss at epoch 8 of 10, step 1200 of 3240: 0.0849
Training loss at epoch 8 of 10, step 1300 of 3240: 0.0908
Training loss at epoch 8 of 10, step 1400 of 3240: 0.0658
Training loss at epoch 8 of 10, step 1500 of 3240: 0.1228
Training loss at epoch 8 of 10, step 1600 of 3240: 0.0834
Training loss at epoch 8 of 10, step 1700 of 3240: 0.1058
Training loss at epoch 8 of 10, step 1800 of 3240: 0.1058
Training loss at epoch 8 of 10, step 1900 of 3240: 0.0557
Training loss at epoch 8 of 10, step 2000 of 3240: 0.0231
Training loss at epoch 8 of 10, step 2100 of 3240: 0.0645
Training loss at epoch 8 of 10, step 2200 of 3240: 0.0358
Training loss at epoch 8 of 10, step 2300 of 3240: 0.1328
Training loss at epoch 8 of 10, step 2400 of 3240: 0.1066
Training loss at epoch 8 of 10, step 2500 of 3240: 0.0569
Training loss at epoch 8 of 10, step 2600 of 3240: 0.0915
Training loss at epoch 8 of 10, step 2700 of 3240: 0.1251
Training loss at epoch 8 of 10, step 2800 of 3240: 0.0664
Training loss at epoch 8 of 10, step 2900 of 3240: 0.0725
Training loss at epoch 8 of 10, step 3000 of 3240: 0.0700
Training loss at epoch 8 of 10, step 3100 of 3240: 0.0573
Training loss at epoch 8 of 10, step 3200 of 3240: 0.0820
Accuracy of network on test set at epoch 8 of 10: 78905/81000 = 97.41%
Training loss at epoch 9 of 10, step 100 of 3240: 0.1070
Training loss at epoch 9 of 10, step 200 of 3240: 0.0382
Training loss at epoch 9 of 10, step 300 of 3240: 0.1052
Training loss at epoch 9 of 10, step 400 of 3240: 0.0526
Training loss at epoch 9 of 10, step 500 of 3240: 0.0659
Training loss at epoch 9 of 10, step 600 of 3240: 0.0787
Training loss at epoch 9 of 10, step 700 of 3240: 0.0762
Training loss at epoch 9 of 10, step 800 of 3240: 0.0976
Training loss at epoch 9 of 10, step 900 of 3240: 0.1029
Training loss at epoch 9 of 10, step 1000 of 3240: 0.1061
Training loss at epoch 9 of 10, step 1100 of 3240: 0.0459
Training loss at epoch 9 of 10, step 1200 of 3240: 0.0733
Training loss at epoch 9 of 10, step 1300 of 3240: 0.0956
Training loss at epoch 9 of 10, step 1400 of 3240: 0.0814
Training loss at epoch 9 of 10, step 1500 of 3240: 0.0760
Training loss at epoch 9 of 10, step 1600 of 3240: 0.0279
Training loss at epoch 9 of 10, step 1700 of 3240: 0.0743
Training loss at epoch 9 of 10, step 1800 of 3240: 0.0710
Training loss at epoch 9 of 10, step 1900 of 3240: 0.0318
Training loss at epoch 9 of 10, step 2000 of 3240: 0.1561
Training loss at epoch 9 of 10, step 2100 of 3240: 0.0493
Training loss at epoch 9 of 10, step 2200 of 3240: 0.0669
Training loss at epoch 9 of 10, step 2300 of 3240: 0.0207
Training loss at epoch 9 of 10, step 2400 of 3240: 0.0895
Training loss at epoch 9 of 10, step 2500 of 3240: 0.0369
Training loss at epoch 9 of 10, step 2600 of 3240: 0.1861
Training loss at epoch 9 of 10, step 2700 of 3240: 0.0908
Training loss at epoch 9 of 10, step 2800 of 3240: 0.0781
Training loss at epoch 9 of 10, step 2900 of 3240: 0.0512
Training loss at epoch 9 of 10, step 3000 of 3240: 0.1029
Training loss at epoch 9 of 10, step 3100 of 3240: 0.0161
Training loss at epoch 9 of 10, step 3200 of 3240: 0.0801
Accuracy of network on test set at epoch 9 of 10: 79020/81000 = 97.56%
Training loss at epoch 10 of 10, step 100 of 3240: 0.0761
Training loss at epoch 10 of 10, step 200 of 3240: 0.0791
Training loss at epoch 10 of 10, step 300 of 3240: 0.0328
Training loss at epoch 10 of 10, step 400 of 3240: 0.0442
Training loss at epoch 10 of 10, step 500 of 3240: 0.0616
Training loss at epoch 10 of 10, step 600 of 3240: 0.0898
Training loss at epoch 10 of 10, step 700 of 3240: 0.0162
Training loss at epoch 10 of 10, step 800 of 3240: 0.0795
Training loss at epoch 10 of 10, step 900 of 3240: 0.0210
Training loss at epoch 10 of 10, step 1000 of 3240: 0.1818
Training loss at epoch 10 of 10, step 1100 of 3240: 0.0410
Training loss at epoch 10 of 10, step 1200 of 3240: 0.0780
Training loss at epoch 10 of 10, step 1300 of 3240: 0.0649
Training loss at epoch 10 of 10, step 1400 of 3240: 0.0310
Training loss at epoch 10 of 10, step 1500 of 3240: 0.0924
Training loss at epoch 10 of 10, step 1600 of 3240: 0.0574
Training loss at epoch 10 of 10, step 1700 of 3240: 0.0631
Training loss at epoch 10 of 10, step 1800 of 3240: 0.0688
Training loss at epoch 10 of 10, step 1900 of 3240: 0.1009
Training loss at epoch 10 of 10, step 2000 of 3240: 0.0468
Training loss at epoch 10 of 10, step 2100 of 3240: 0.0897
Training loss at epoch 10 of 10, step 2200 of 3240: 0.0803
Training loss at epoch 10 of 10, step 2300 of 3240: 0.0776
Training loss at epoch 10 of 10, step 2400 of 3240: 0.0522
Training loss at epoch 10 of 10, step 2500 of 3240: 0.0300
Training loss at epoch 10 of 10, step 2600 of 3240: 0.0591
Training loss at epoch 10 of 10, step 2700 of 3240: 0.0597
Training loss at epoch 10 of 10, step 2800 of 3240: 0.0285
Training loss at epoch 10 of 10, step 2900 of 3240: 0.0749
Training loss at epoch 10 of 10, step 3000 of 3240: 0.0681
Training loss at epoch 10 of 10, step 3100 of 3240: 0.0599
Training loss at epoch 10 of 10, step 3200 of 3240: 0.0675
Accuracy of network on test set at epoch 10 of 10: 78812/81000 = 97.30%
Training time: 2878.8 seconds.
Training loss plot saved in /Plots.
Testing Accuracy plot saved in /Plots.
             building  barren land  trees  grassland  road  water
building         3409            3      0          0    61      0
barren land        23        17878      6        789     2      0
trees               0           11  13876        137     8      0
grassland           0          472    303      11640    38      0
road              282            3      0         30  1941      0
water               0            0      0          0    20  30068
Accuracy rate: 97.30%
Misclassifcation rate: 2.70%
Confusion matrix plot saved in /Plots.
kernels plot saved in /Plots.
