Sample image grid saved to /Plots with classes:
grassland, water, building, water, grassland, water, water, trees, trees, trees, water, barren land, water, trees, barren land, grassland, water, barren land, water, trees, water, grassland, trees, trees, barren land, grassland, water, trees, water, grassland, barren land, barren land, barren land, building, trees, barren land, trees, water, grassland, barren land, trees, water, barren land, barren land, building, water, water, water, grassland, trees, building, building, water, barren land, water, trees, barren land, water, water, water, barren land, water, trees, water, water, grassland, water, trees, water, grassland, building, trees, trees, road, trees, barren land, barren land, water, water, water, road, barren land, water, water, barren land, barren land, water, trees, water, water, water, water, water, water, barren land, grassland, grassland, water, trees, building
NETWORK PARAMETERS:
Batch size: 100
Epochs: 10
Learning rate: 0.010000
Momentum: 0.900000
Weight Decay: 0.000500
Input channels: 4
Input dimensions: 28

NETWORK CONFIGURATION:
0 -> QuasiAlex (
  (conv1): Conv2d(4, 12, kernel_size=(11, 11), stride=(1, 1))
  (conv2): Conv2d(12, 32, kernel_size=(5, 5), stride=(1, 1))
  (conv3): Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1))
  (conv4): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv5): Conv2d(48, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (pool): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))
  (fc1): Linear (1152 -> 24)
  (fc2): Linear (24 -> 24)
  (fc3): Linear (24 -> 6)
)
1 -> Conv2d(4, 12, kernel_size=(11, 11), stride=(1, 1))
2 -> Conv2d(12, 32, kernel_size=(5, 5), stride=(1, 1))
3 -> Conv2d(32, 48, kernel_size=(3, 3), stride=(1, 1))
4 -> Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
5 -> Conv2d(48, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
6 -> MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))
7 -> Linear (1152 -> 24)
8 -> Linear (24 -> 24)
9 -> Linear (24 -> 6)
Training loss at epoch 1 of 10, step 100 of 3240: 1.3244
Training loss at epoch 1 of 10, step 200 of 3240: 0.8224
Training loss at epoch 1 of 10, step 300 of 3240: 0.7394
Training loss at epoch 1 of 10, step 400 of 3240: 1.1846
Training loss at epoch 1 of 10, step 500 of 3240: 0.9207
Training loss at epoch 1 of 10, step 600 of 3240: 0.7015
Training loss at epoch 1 of 10, step 700 of 3240: 0.5982
Training loss at epoch 1 of 10, step 800 of 3240: 0.4861
Training loss at epoch 1 of 10, step 900 of 3240: 0.7417
Training loss at epoch 1 of 10, step 1000 of 3240: 0.5204
Training loss at epoch 1 of 10, step 1100 of 3240: 0.4065
Training loss at epoch 1 of 10, step 1200 of 3240: 0.3052
Training loss at epoch 1 of 10, step 1300 of 3240: 0.2733
Training loss at epoch 1 of 10, step 1400 of 3240: 0.2940
Training loss at epoch 1 of 10, step 1500 of 3240: 0.1515
Training loss at epoch 1 of 10, step 1600 of 3240: 0.3888
Training loss at epoch 1 of 10, step 1700 of 3240: 0.3232
Training loss at epoch 1 of 10, step 1800 of 3240: 0.3939
Training loss at epoch 1 of 10, step 1900 of 3240: 0.1924
Training loss at epoch 1 of 10, step 2000 of 3240: 0.2793
Training loss at epoch 1 of 10, step 2100 of 3240: 0.4056
Training loss at epoch 1 of 10, step 2200 of 3240: 0.2767
Training loss at epoch 1 of 10, step 2300 of 3240: 0.3061
Training loss at epoch 1 of 10, step 2400 of 3240: 0.3052
Training loss at epoch 1 of 10, step 2500 of 3240: 0.3338
Training loss at epoch 1 of 10, step 2600 of 3240: 0.2897
Training loss at epoch 1 of 10, step 2700 of 3240: 0.3690
Training loss at epoch 1 of 10, step 2800 of 3240: 0.2817
Training loss at epoch 1 of 10, step 2900 of 3240: 0.3229
Training loss at epoch 1 of 10, step 3000 of 3240: 0.2299
Training loss at epoch 1 of 10, step 3100 of 3240: 0.1944
Training loss at epoch 1 of 10, step 3200 of 3240: 0.1731
Accuracy of network on test set at epoch 1 of 10: 74257/81000 = 91.68%
Training loss at epoch 2 of 10, step 100 of 3240: 0.2150
Training loss at epoch 2 of 10, step 200 of 3240: 0.0784
Training loss at epoch 2 of 10, step 300 of 3240: 0.3108
Training loss at epoch 2 of 10, step 400 of 3240: 0.1992
Training loss at epoch 2 of 10, step 500 of 3240: 0.2556
Training loss at epoch 2 of 10, step 600 of 3240: 0.0891
Training loss at epoch 2 of 10, step 700 of 3240: 0.1134
Training loss at epoch 2 of 10, step 800 of 3240: 0.2128
Training loss at epoch 2 of 10, step 900 of 3240: 0.2551
Training loss at epoch 2 of 10, step 1000 of 3240: 0.2301
Training loss at epoch 2 of 10, step 1100 of 3240: 0.0829
Training loss at epoch 2 of 10, step 1200 of 3240: 0.1305
Training loss at epoch 2 of 10, step 1300 of 3240: 0.0835
Training loss at epoch 2 of 10, step 1400 of 3240: 0.2192
Training loss at epoch 2 of 10, step 1500 of 3240: 0.1530
Training loss at epoch 2 of 10, step 1600 of 3240: 0.0754
Training loss at epoch 2 of 10, step 1700 of 3240: 0.1939
Training loss at epoch 2 of 10, step 1800 of 3240: 0.1094
Training loss at epoch 2 of 10, step 1900 of 3240: 0.1272
Training loss at epoch 2 of 10, step 2000 of 3240: 0.1482
Training loss at epoch 2 of 10, step 2100 of 3240: 0.1205
Training loss at epoch 2 of 10, step 2200 of 3240: 0.1602
Training loss at epoch 2 of 10, step 2300 of 3240: 0.1579
Training loss at epoch 2 of 10, step 2400 of 3240: 0.1523
Training loss at epoch 2 of 10, step 2500 of 3240: 0.1222
Training loss at epoch 2 of 10, step 2600 of 3240: 0.1403
Training loss at epoch 2 of 10, step 2700 of 3240: 0.1784
Training loss at epoch 2 of 10, step 2800 of 3240: 0.0864
Training loss at epoch 2 of 10, step 2900 of 3240: 0.1572
Training loss at epoch 2 of 10, step 3000 of 3240: 0.0892
Training loss at epoch 2 of 10, step 3100 of 3240: 0.1700
Training loss at epoch 2 of 10, step 3200 of 3240: 0.1777
Accuracy of network on test set at epoch 2 of 10: 77358/81000 = 95.50%
Training loss at epoch 3 of 10, step 100 of 3240: 0.1915
Training loss at epoch 3 of 10, step 200 of 3240: 0.1665
Training loss at epoch 3 of 10, step 300 of 3240: 0.1198
Training loss at epoch 3 of 10, step 400 of 3240: 0.1611
Training loss at epoch 3 of 10, step 500 of 3240: 0.1155
Training loss at epoch 3 of 10, step 600 of 3240: 0.1726
Training loss at epoch 3 of 10, step 700 of 3240: 0.3322
Training loss at epoch 3 of 10, step 800 of 3240: 0.1673
Training loss at epoch 3 of 10, step 900 of 3240: 0.2458
Training loss at epoch 3 of 10, step 1000 of 3240: 0.0764
Training loss at epoch 3 of 10, step 1100 of 3240: 0.1220
Training loss at epoch 3 of 10, step 1200 of 3240: 0.1440
Training loss at epoch 3 of 10, step 1300 of 3240: 0.2332
Training loss at epoch 3 of 10, step 1400 of 3240: 0.1427
Training loss at epoch 3 of 10, step 1500 of 3240: 0.1169
Training loss at epoch 3 of 10, step 1600 of 3240: 0.1475
Training loss at epoch 3 of 10, step 1700 of 3240: 0.1278
Training loss at epoch 3 of 10, step 1800 of 3240: 0.1621
Training loss at epoch 3 of 10, step 1900 of 3240: 0.1352
Training loss at epoch 3 of 10, step 2000 of 3240: 0.0840
Training loss at epoch 3 of 10, step 2100 of 3240: 0.1126
Training loss at epoch 3 of 10, step 2200 of 3240: 0.0980
Training loss at epoch 3 of 10, step 2300 of 3240: 0.1441
Training loss at epoch 3 of 10, step 2400 of 3240: 0.1040
Training loss at epoch 3 of 10, step 2500 of 3240: 0.1908
Training loss at epoch 3 of 10, step 2600 of 3240: 0.1683
Training loss at epoch 3 of 10, step 2700 of 3240: 0.2187
Training loss at epoch 3 of 10, step 2800 of 3240: 0.1159
Training loss at epoch 3 of 10, step 2900 of 3240: 0.1564
Training loss at epoch 3 of 10, step 3000 of 3240: 0.2026
Training loss at epoch 3 of 10, step 3100 of 3240: 0.1862
Training loss at epoch 3 of 10, step 3200 of 3240: 0.0790
Accuracy of network on test set at epoch 3 of 10: 76176/81000 = 94.04%
Training loss at epoch 4 of 10, step 100 of 3240: 0.1906
Training loss at epoch 4 of 10, step 200 of 3240: 0.0598
Training loss at epoch 4 of 10, step 300 of 3240: 0.1142
Training loss at epoch 4 of 10, step 400 of 3240: 0.1474
Training loss at epoch 4 of 10, step 500 of 3240: 0.1366
Training loss at epoch 4 of 10, step 600 of 3240: 0.0861
Training loss at epoch 4 of 10, step 700 of 3240: 0.2063
Training loss at epoch 4 of 10, step 800 of 3240: 0.0753
Training loss at epoch 4 of 10, step 900 of 3240: 0.1464
Training loss at epoch 4 of 10, step 1000 of 3240: 0.0947
Training loss at epoch 4 of 10, step 1100 of 3240: 0.0541
Training loss at epoch 4 of 10, step 1200 of 3240: 0.0911
Training loss at epoch 4 of 10, step 1300 of 3240: 0.1127
Training loss at epoch 4 of 10, step 1400 of 3240: 0.1470
Training loss at epoch 4 of 10, step 1500 of 3240: 0.1417
Training loss at epoch 4 of 10, step 1600 of 3240: 0.0724
Training loss at epoch 4 of 10, step 1700 of 3240: 0.1114
Training loss at epoch 4 of 10, step 1800 of 3240: 0.1295
Training loss at epoch 4 of 10, step 1900 of 3240: 0.0796
Training loss at epoch 4 of 10, step 2000 of 3240: 0.1043
Training loss at epoch 4 of 10, step 2100 of 3240: 0.0998
Training loss at epoch 4 of 10, step 2200 of 3240: 0.0906
Training loss at epoch 4 of 10, step 2300 of 3240: 0.1944
Training loss at epoch 4 of 10, step 2400 of 3240: 0.1045
Training loss at epoch 4 of 10, step 2500 of 3240: 0.0646
Training loss at epoch 4 of 10, step 2600 of 3240: 0.1332
Training loss at epoch 4 of 10, step 2700 of 3240: 0.0951
Training loss at epoch 4 of 10, step 2800 of 3240: 0.1244
Training loss at epoch 4 of 10, step 2900 of 3240: 0.2163
Training loss at epoch 4 of 10, step 3000 of 3240: 0.1359
Training loss at epoch 4 of 10, step 3100 of 3240: 0.0818
Training loss at epoch 4 of 10, step 3200 of 3240: 0.1020
Accuracy of network on test set at epoch 4 of 10: 77575/81000 = 95.77%
Training loss at epoch 5 of 10, step 100 of 3240: 0.0586
Training loss at epoch 5 of 10, step 200 of 3240: 0.0510
Training loss at epoch 5 of 10, step 300 of 3240: 0.1345
Training loss at epoch 5 of 10, step 400 of 3240: 0.1216
Training loss at epoch 5 of 10, step 500 of 3240: 0.0981
Training loss at epoch 5 of 10, step 600 of 3240: 0.0450
Training loss at epoch 5 of 10, step 700 of 3240: 0.1097
Training loss at epoch 5 of 10, step 800 of 3240: 0.1461
Training loss at epoch 5 of 10, step 900 of 3240: 0.1068
Training loss at epoch 5 of 10, step 1000 of 3240: 0.0869
Training loss at epoch 5 of 10, step 1100 of 3240: 0.1223
Training loss at epoch 5 of 10, step 1200 of 3240: 0.1181
Training loss at epoch 5 of 10, step 1300 of 3240: 0.1167
Training loss at epoch 5 of 10, step 1400 of 3240: 0.1011
Training loss at epoch 5 of 10, step 1500 of 3240: 0.1790
Training loss at epoch 5 of 10, step 1600 of 3240: 0.0467
Training loss at epoch 5 of 10, step 1700 of 3240: 0.1098
Training loss at epoch 5 of 10, step 1800 of 3240: 0.1457
Training loss at epoch 5 of 10, step 1900 of 3240: 0.1096
Training loss at epoch 5 of 10, step 2000 of 3240: 0.1967
Training loss at epoch 5 of 10, step 2100 of 3240: 0.1511
Training loss at epoch 5 of 10, step 2200 of 3240: 0.0597
Training loss at epoch 5 of 10, step 2300 of 3240: 0.1248
Training loss at epoch 5 of 10, step 2400 of 3240: 0.0742
Training loss at epoch 5 of 10, step 2500 of 3240: 0.0542
Training loss at epoch 5 of 10, step 2600 of 3240: 0.0996
Training loss at epoch 5 of 10, step 2700 of 3240: 0.0783
Training loss at epoch 5 of 10, step 2800 of 3240: 0.0770
Training loss at epoch 5 of 10, step 2900 of 3240: 0.0800
Training loss at epoch 5 of 10, step 3000 of 3240: 0.1888
Training loss at epoch 5 of 10, step 3100 of 3240: 0.0938
Training loss at epoch 5 of 10, step 3200 of 3240: 0.1229
Accuracy of network on test set at epoch 5 of 10: 77950/81000 = 96.23%
Training loss at epoch 6 of 10, step 100 of 3240: 0.1217
Training loss at epoch 6 of 10, step 200 of 3240: 0.1054
Training loss at epoch 6 of 10, step 300 of 3240: 0.0676
Training loss at epoch 6 of 10, step 400 of 3240: 0.0896
Training loss at epoch 6 of 10, step 500 of 3240: 0.0736
Training loss at epoch 6 of 10, step 600 of 3240: 0.1370
Training loss at epoch 6 of 10, step 700 of 3240: 0.1458
Training loss at epoch 6 of 10, step 800 of 3240: 0.0969
Training loss at epoch 6 of 10, step 900 of 3240: 0.0400
Training loss at epoch 6 of 10, step 1000 of 3240: 0.0824
Training loss at epoch 6 of 10, step 1100 of 3240: 0.0410
Training loss at epoch 6 of 10, step 1200 of 3240: 0.0937
Training loss at epoch 6 of 10, step 1300 of 3240: 0.0753
Training loss at epoch 6 of 10, step 1400 of 3240: 0.1023
Training loss at epoch 6 of 10, step 1500 of 3240: 0.0633
Training loss at epoch 6 of 10, step 1600 of 3240: 0.1173
Training loss at epoch 6 of 10, step 1700 of 3240: 0.0937
Training loss at epoch 6 of 10, step 1800 of 3240: 0.0776
Training loss at epoch 6 of 10, step 1900 of 3240: 0.0810
Training loss at epoch 6 of 10, step 2000 of 3240: 0.2598
Training loss at epoch 6 of 10, step 2100 of 3240: 0.1295
Training loss at epoch 6 of 10, step 2200 of 3240: 0.0697
Training loss at epoch 6 of 10, step 2300 of 3240: 0.1348
Training loss at epoch 6 of 10, step 2400 of 3240: 0.1034
Training loss at epoch 6 of 10, step 2500 of 3240: 0.1072
Training loss at epoch 6 of 10, step 2600 of 3240: 0.0307
Training loss at epoch 6 of 10, step 2700 of 3240: 0.0456
Training loss at epoch 6 of 10, step 2800 of 3240: 0.0819
Training loss at epoch 6 of 10, step 2900 of 3240: 0.0737
Training loss at epoch 6 of 10, step 3000 of 3240: 0.0995
Training loss at epoch 6 of 10, step 3100 of 3240: 0.0607
Training loss at epoch 6 of 10, step 3200 of 3240: 0.1303
Accuracy of network on test set at epoch 6 of 10: 76296/81000 = 94.19%
Training loss at epoch 7 of 10, step 100 of 3240: 0.1196
Training loss at epoch 7 of 10, step 200 of 3240: 0.1240
Training loss at epoch 7 of 10, step 300 of 3240: 0.1419
Training loss at epoch 7 of 10, step 400 of 3240: 0.0397
Training loss at epoch 7 of 10, step 500 of 3240: 0.0637
Training loss at epoch 7 of 10, step 600 of 3240: 0.0486
Training loss at epoch 7 of 10, step 700 of 3240: 0.1247
Training loss at epoch 7 of 10, step 800 of 3240: 0.1352
Training loss at epoch 7 of 10, step 900 of 3240: 0.0975
Training loss at epoch 7 of 10, step 1000 of 3240: 0.1890
Training loss at epoch 7 of 10, step 1100 of 3240: 0.0455
Training loss at epoch 7 of 10, step 1200 of 3240: 0.0692
Training loss at epoch 7 of 10, step 1300 of 3240: 0.1449
Training loss at epoch 7 of 10, step 1400 of 3240: 0.0986
Training loss at epoch 7 of 10, step 1500 of 3240: 0.1012
Training loss at epoch 7 of 10, step 1600 of 3240: 0.0858
Training loss at epoch 7 of 10, step 1700 of 3240: 0.0872
Training loss at epoch 7 of 10, step 1800 of 3240: 0.1817
Training loss at epoch 7 of 10, step 1900 of 3240: 0.0379
Training loss at epoch 7 of 10, step 2000 of 3240: 0.1101
Training loss at epoch 7 of 10, step 2100 of 3240: 0.0505
Training loss at epoch 7 of 10, step 2200 of 3240: 0.0890
Training loss at epoch 7 of 10, step 2300 of 3240: 0.1268
Training loss at epoch 7 of 10, step 2400 of 3240: 0.0838
Training loss at epoch 7 of 10, step 2500 of 3240: 0.0453
Training loss at epoch 7 of 10, step 2600 of 3240: 0.1089
Training loss at epoch 7 of 10, step 2700 of 3240: 0.1026
Training loss at epoch 7 of 10, step 2800 of 3240: 0.1123
Training loss at epoch 7 of 10, step 2900 of 3240: 0.0700
Training loss at epoch 7 of 10, step 3000 of 3240: 0.0298
Training loss at epoch 7 of 10, step 3100 of 3240: 0.1395
Training loss at epoch 7 of 10, step 3200 of 3240: 0.0836
Accuracy of network on test set at epoch 7 of 10: 76891/81000 = 94.93%
Training loss at epoch 8 of 10, step 100 of 3240: 0.1380
Training loss at epoch 8 of 10, step 200 of 3240: 0.0660
Training loss at epoch 8 of 10, step 300 of 3240: 0.1115
Training loss at epoch 8 of 10, step 400 of 3240: 0.0680
Training loss at epoch 8 of 10, step 500 of 3240: 0.0666
Training loss at epoch 8 of 10, step 600 of 3240: 0.0821
Training loss at epoch 8 of 10, step 700 of 3240: 0.0831
Training loss at epoch 8 of 10, step 800 of 3240: 0.0540
Training loss at epoch 8 of 10, step 900 of 3240: 0.0782
Training loss at epoch 8 of 10, step 1000 of 3240: 0.0746
Training loss at epoch 8 of 10, step 1100 of 3240: 0.0667
Training loss at epoch 8 of 10, step 1200 of 3240: 0.0869
Training loss at epoch 8 of 10, step 1300 of 3240: 0.1306
Training loss at epoch 8 of 10, step 1400 of 3240: 0.0684
Training loss at epoch 8 of 10, step 1500 of 3240: 0.0654
Training loss at epoch 8 of 10, step 1600 of 3240: 0.0973
Training loss at epoch 8 of 10, step 1700 of 3240: 0.1098
Training loss at epoch 8 of 10, step 1800 of 3240: 0.1157
Training loss at epoch 8 of 10, step 1900 of 3240: 0.0691
Training loss at epoch 8 of 10, step 2000 of 3240: 0.0470
Training loss at epoch 8 of 10, step 2100 of 3240: 0.0556
Training loss at epoch 8 of 10, step 2200 of 3240: 0.1011
Training loss at epoch 8 of 10, step 2300 of 3240: 0.2480
Training loss at epoch 8 of 10, step 2400 of 3240: 0.0855
Training loss at epoch 8 of 10, step 2500 of 3240: 0.0990
Training loss at epoch 8 of 10, step 2600 of 3240: 0.0618
Training loss at epoch 8 of 10, step 2700 of 3240: 0.0778
Training loss at epoch 8 of 10, step 2800 of 3240: 0.1650
Training loss at epoch 8 of 10, step 2900 of 3240: 0.0675
Training loss at epoch 8 of 10, step 3000 of 3240: 0.1709
Training loss at epoch 8 of 10, step 3100 of 3240: 0.0534
Training loss at epoch 8 of 10, step 3200 of 3240: 0.0646
Accuracy of network on test set at epoch 8 of 10: 78525/81000 = 96.94%
Training loss at epoch 9 of 10, step 100 of 3240: 0.0927
Training loss at epoch 9 of 10, step 200 of 3240: 0.1344
Training loss at epoch 9 of 10, step 300 of 3240: 0.0376
Training loss at epoch 9 of 10, step 400 of 3240: 0.1210
Training loss at epoch 9 of 10, step 500 of 3240: 0.1518
Training loss at epoch 9 of 10, step 600 of 3240: 0.0925
Training loss at epoch 9 of 10, step 700 of 3240: 0.0518
Training loss at epoch 9 of 10, step 800 of 3240: 0.1563
Training loss at epoch 9 of 10, step 900 of 3240: 0.0690
Training loss at epoch 9 of 10, step 1000 of 3240: 0.0432
Training loss at epoch 9 of 10, step 1100 of 3240: 0.1522
Training loss at epoch 9 of 10, step 1200 of 3240: 0.0504
Training loss at epoch 9 of 10, step 1300 of 3240: 0.0624
Training loss at epoch 9 of 10, step 1400 of 3240: 0.0717
Training loss at epoch 9 of 10, step 1500 of 3240: 0.0635
Training loss at epoch 9 of 10, step 1600 of 3240: 0.2217
Training loss at epoch 9 of 10, step 1700 of 3240: 0.1792
Training loss at epoch 9 of 10, step 1800 of 3240: 0.0595
Training loss at epoch 9 of 10, step 1900 of 3240: 0.1524
Training loss at epoch 9 of 10, step 2000 of 3240: 0.1108
Training loss at epoch 9 of 10, step 2100 of 3240: 0.1118
Training loss at epoch 9 of 10, step 2200 of 3240: 0.0690
Training loss at epoch 9 of 10, step 2300 of 3240: 0.0565
Training loss at epoch 9 of 10, step 2400 of 3240: 0.1192
Training loss at epoch 9 of 10, step 2500 of 3240: 0.0823
Training loss at epoch 9 of 10, step 2600 of 3240: 0.0312
Training loss at epoch 9 of 10, step 2700 of 3240: 0.0407
Training loss at epoch 9 of 10, step 2800 of 3240: 0.0876
Training loss at epoch 9 of 10, step 2900 of 3240: 0.2495
Training loss at epoch 9 of 10, step 3000 of 3240: 0.1000
Training loss at epoch 9 of 10, step 3100 of 3240: 0.0362
Training loss at epoch 9 of 10, step 3200 of 3240: 0.0731
Accuracy of network on test set at epoch 9 of 10: 77915/81000 = 96.19%
Training loss at epoch 10 of 10, step 100 of 3240: 0.0612
Training loss at epoch 10 of 10, step 200 of 3240: 0.0886
Training loss at epoch 10 of 10, step 300 of 3240: 0.1316
Training loss at epoch 10 of 10, step 400 of 3240: 0.0396
Training loss at epoch 10 of 10, step 500 of 3240: 0.0984
Training loss at epoch 10 of 10, step 600 of 3240: 0.0425
Training loss at epoch 10 of 10, step 700 of 3240: 0.0609
Training loss at epoch 10 of 10, step 800 of 3240: 0.2518
Training loss at epoch 10 of 10, step 900 of 3240: 0.1052
Training loss at epoch 10 of 10, step 1000 of 3240: 0.0328
Training loss at epoch 10 of 10, step 1100 of 3240: 0.1416
Training loss at epoch 10 of 10, step 1200 of 3240: 0.1207
Training loss at epoch 10 of 10, step 1300 of 3240: 0.1326
Training loss at epoch 10 of 10, step 1400 of 3240: 0.1024
Training loss at epoch 10 of 10, step 1500 of 3240: 0.1080
Training loss at epoch 10 of 10, step 1600 of 3240: 0.0800
Training loss at epoch 10 of 10, step 1700 of 3240: 0.0860
Training loss at epoch 10 of 10, step 1800 of 3240: 0.0479
Training loss at epoch 10 of 10, step 1900 of 3240: 0.0511
Training loss at epoch 10 of 10, step 2000 of 3240: 0.0750
Training loss at epoch 10 of 10, step 2100 of 3240: 0.0213
Training loss at epoch 10 of 10, step 2200 of 3240: 0.1293
Training loss at epoch 10 of 10, step 2300 of 3240: 0.0357
Training loss at epoch 10 of 10, step 2400 of 3240: 0.0569
Training loss at epoch 10 of 10, step 2500 of 3240: 0.1465
Training loss at epoch 10 of 10, step 2600 of 3240: 0.0495
Training loss at epoch 10 of 10, step 2700 of 3240: 0.0568
Training loss at epoch 10 of 10, step 2800 of 3240: 0.0896
Training loss at epoch 10 of 10, step 2900 of 3240: 0.0395
Training loss at epoch 10 of 10, step 3000 of 3240: 0.0716
Training loss at epoch 10 of 10, step 3100 of 3240: 0.1106
Training loss at epoch 10 of 10, step 3200 of 3240: 0.1346
Accuracy of network on test set at epoch 10 of 10: 78713/81000 = 97.18%
Training time: 3243.2 seconds.
Training loss plot saved in /Plots.
Testing Accuracy plot saved in /Plots.
             building  barren land  trees  grassland  road  water
building         3198            2      0          0    41      0
barren land         1        17261      4        200     3      0
trees               0           11  14007        179    30      0
grassland           0         1089    173      12216    12      0
road              499            4      1          1  1963      0
water              16            0      0          0    21  30068
Accuracy rate: 97.18%
Misclassifcation rate: 2.82%
Confusion matrix plot saved in /Plots.
